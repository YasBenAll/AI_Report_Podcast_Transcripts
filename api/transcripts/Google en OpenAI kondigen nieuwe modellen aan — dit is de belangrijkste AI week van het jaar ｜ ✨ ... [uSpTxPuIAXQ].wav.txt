Video title: Google en OpenAI kondigen nieuwe modellen aan — dit is de belangrijkste AI week van het jaar ｜ ✨ ...
Youtube video code: uSpTxPuIAXQ
Last modified time: 2024-12-12 20:12:50

------------------ 

[0.00 --> 1.16]  18 plus speelbewust.
[1.70 --> 4.00]  1 januari valt die gegarandeerd.
[4.30 --> 7.60]  De postcode kan je van 59,7 miljoen.
[7.94 --> 11.72]  Het kan overal in Nederland gebeuren, dus ook bij u in de straat.
[12.46 --> 14.58]  59,7 miljoen.
[14.94 --> 15.72]  Speel ook mee.
[16.76 --> 19.36]  Ga naar postcode loterij.nl
[19.36 --> 23.06]  Voor je gaat luisteren, heel even dit.
[23.60 --> 29.28]  In de nieuwe podcast Veldheren neem ik, Jos de Groot, jou iedere donderdag mee voorbij de frontlijn in Oekraïne.
[29.28 --> 33.38]  Dat doe ik samen met generaals buitendienst Peter van Um en Mart de Kuif.
[33.80 --> 35.20]  Zij hebben één duidelijk doel.
[35.42 --> 37.38]  Aan jou uitleggen hoe oorlog werkt.
[37.92 --> 39.94]  Volg Veldheren in jouw favoriete podcast app.
[44.32 --> 48.58]  Welkom bij Poki, de Nederlandse podcast over kunstmatige intelligentie.
[49.04 --> 53.46]  Waar we uitzoeken welke invloed jij gaat hebben op ons werk, ons leven en de samenleving.
[53.66 --> 55.22]  Tegenover mij zit Wietsehagen.
[55.22 --> 60.60]  En het was de grootste week met het meest AI nieuws van het jaar, kunnen we wel zeggen.
[61.30 --> 64.32]  We duiken erin en het is een ongelofelijke hoeveelheid aankondigingen.
[64.64 --> 68.18]  We beginnen met Google, die de tweede versie van Gemini aankondigde.
[68.32 --> 76.32]  Een zogenaamd Omni-model dat alles kan, inclusief je computer bedienen en je ogen, oren en stem zijn in de echte wereld.
[76.32 --> 81.30]  We zijn er een beetje van ondersteboven en vertellen je hoe je de nieuwe functionaliteiten vandaag al kan testen.
[81.92 --> 88.20]  En daarnaast brengt OpenAI nu iedere dag nieuws uit van de lang verwachte lancering van Sora, de videogenerator.
[88.74 --> 94.14]  En de niet-preview versie van O1, het grote reasoning model van OpenAI.
[94.34 --> 97.12]  Brengt het bedrijf ook allerlei nieuwe features in Chatsypte uit.
[97.26 --> 98.88]  We bevatten al het nieuws voor je samen.
[99.84 --> 102.24]  Dat en veel meer vandaag in Poki.
[102.74 --> 103.16]  Veel plezier.
[103.16 --> 118.70]  Oké, ik heb me door deze intro toch wel een beetje heen geworsteld.
[118.94 --> 124.84]  Want ik moet je zeggen, ik ervaar wel stress over deze aflevering die we nu gaan maken.
[124.98 --> 127.44]  Ja, ik ontmoette een gestresste Alexander vanochtend.
[127.44 --> 133.74]  Want ik heb echt vier uur zitten lezen om gewoon een baseline idee te krijgen van wat er de afgelopen weken is gebeurd.
[133.84 --> 134.68]  Het is insane.
[134.82 --> 137.94]  Wat er bij Google is gebeurd, alleen al bij Google en bij OpenAI.
[139.00 --> 141.24]  Ja, we kunnen daar gewoon de hele middag over doorpraten.
[142.24 --> 146.48]  Maar dat ik echt denk, hoe doen de meeste mensen dit?
[146.60 --> 148.18]  Dit is niet bij te houden voor mensen.
[148.30 --> 152.06]  Ik bedoel, ik snap dat wij dit doen en dan aan de mensen praten in de podcast.
[152.06 --> 153.62]  Maar hoe...
[153.62 --> 158.80]  Ik denk dat de meeste mensen die nu hier buiten op straat lopen, gewoon helemaal geen idee hebben van wat er allemaal gebeurd is.
[159.44 --> 161.02]  In de afgelopen week.
[161.24 --> 161.38]  Ja.
[161.82 --> 167.72]  En je moet ook nog een beetje door al die headlines heen kunnen scrollen om de impact ervan in te kunnen schatten.
[167.82 --> 168.72]  Of de relevantie ervan.
[169.18 --> 173.60]  Sommige dingen zijn een soort van, ja oké, Apple Intelligence is nu daadwerkelijk beschikbaar.
[173.60 --> 178.86]  En dan, oh ja, je kunt nu ook, het is een hele goede voice doen als notebook-alem, als ontwikkelaar.
[179.58 --> 181.42]  Dus dat is best wel, die staan in dezelfde rij.
[181.60 --> 182.36]  Dus dat kooien dan langs.
[182.46 --> 183.40]  Ja, ja, ja.
[183.48 --> 184.42]  Dat hebben wij wel gedaan.
[185.32 --> 187.02]  Ja, nou goed, we hebben alles gelezen.
[187.16 --> 189.82]  In ieder geval voor zover dat kon.
[190.32 --> 193.22]  En we gaan proberen samen te vatten deze aflevering.
[193.58 --> 194.64]  Dus laten we beginnen met Google.
[194.80 --> 196.48]  Want Google is wakker geworden.
[196.64 --> 198.40]  Dat is één ding wat we wel kunnen vaststellen.
[198.40 --> 203.22]  We hebben heel lang over Google en AI gepraat als een soort van AI-apologeten.
[203.60 --> 204.54]  Die heel lang hebben geroepen.
[204.60 --> 208.10]  Maar ja, maar wij zijn heel, wij waren al heel vroeg erbij met AI-hoog.
[208.40 --> 211.68]  Om elke keer te compenseren voor het feit dat ze overal achteraan hollen.
[212.52 --> 218.20]  Maar terwijl OpenAI met 12 Days of Shipmas bezig was.
[218.44 --> 227.98]  En de hele tijd leek de, ja, de aandacht te trekken met een soort van drip van nieuwe dingen die ze uitbrengen op dit moment.
[228.88 --> 233.36]  Is toch de shine op dit moment gestolen door Google, zou ik zeggen.
[233.60 --> 234.42]  Ja, die hebben hem ook.
[234.48 --> 237.46]  Het was tot nu toe heel vaak dat Google iets deed, dan OpenAI eroverheen.
[237.58 --> 237.70]  Ja.
[237.96 --> 240.56]  En nu speelt Google blijkbaar ook mee in dit spelletje.
[240.66 --> 242.14]  En gaat nog een keer doorheen lopen releasen.
[242.22 --> 242.32]  Ja.
[243.10 --> 244.56]  Kan je hele complotten achterdenken.
[244.68 --> 248.66]  Ik denk omeens zijn dat heel veel van dit soort marketing, kwartaal schedules ook gewoon een beetje sigroon lopen.
[248.78 --> 249.44]  Als ik er eerlijk ben.
[249.58 --> 250.18]  Ja, eind van het jaar.
[250.24 --> 251.12]  Ja, het gebeurt gewoon.
[251.26 --> 251.88]  Het is gewoon nu.
[251.98 --> 252.64]  Het is aan de hand.
[252.82 --> 254.00]  Mensen willen ook op vakantie straks.
[254.00 --> 256.72]  Laten we eerst op hoofdlijnen praten wat Google heeft gedaan.
[256.82 --> 258.12]  We gaan het straks over OpenAI hebben.
[258.26 --> 259.60]  Want er valt ook genoeg over te zeggen.
[259.72 --> 261.96]  Maar laten we eerst op hoofdlijnen over wat Google heeft gedaan.
[262.56 --> 266.68]  Wat ik heb opgeschreven, je moet me maar aanvullen wietse, is Gemini 2.0 Flash.
[267.14 --> 269.92]  Een nieuwe kleine model wat beter is dan een heel groot model.
[270.60 --> 271.46]  Project Astra.
[271.66 --> 274.90]  Dat is een persoonlijke AI-assistent die je omgeving begrijpt.
[274.98 --> 276.10]  Gaan we uitgebaat bij stilstaan.
[276.10 --> 277.74]  Project Mariner.
[278.18 --> 281.54]  Een soort plug-in, een extensie voor Chrome.
[281.80 --> 284.12]  Waarmee je je AI je computer kan laten bedienen.
[284.76 --> 287.48]  En een feature van Gemini, namelijk Deep Research.
[287.76 --> 291.14]  Volgens mij mist er dan nog een programmeertool die ze hebben uitgebracht.
[291.26 --> 291.74]  Jules.
[292.10 --> 292.26]  Ja.
[292.82 --> 293.68]  Heb ik dan alles?
[294.12 --> 294.44]  Ja.
[295.46 --> 297.32]  Je kan op een gegeven moment ook teveel bespreken.
[298.08 --> 299.44]  Nee, maar dit zijn wel de belangenen.
[299.48 --> 300.44]  En dit is alleen nog maar Google.
[300.76 --> 300.98]  Ik bedoel.
[301.04 --> 301.60]  Ja, nee, daarom.
[301.64 --> 302.74]  Maar laten we erin duiken wietse.
[302.78 --> 303.44]  Waar wil je beginnen?
[303.44 --> 307.94]  Wat vind je het bijzonderst of het belangrijkst?
[308.10 --> 309.88]  Nou, ik denk wel dat...
[309.88 --> 313.52]  We hebben die metafoor van een soort hardloopwedstrijd wel eens gebruikt.
[313.66 --> 315.56]  Dat je allemaal mensen in hun eigen baantje ziet rennen.
[315.66 --> 318.66]  En dat dan al die grote bedrijven met hun taalmodellen naast elkaar rennen.
[318.74 --> 319.54]  En achter elkaar rennen.
[319.62 --> 320.52]  En voorbij elkaar rennen.
[321.30 --> 323.56]  En dan doet Google nu een soort bol.
[323.78 --> 325.68]  Als in die begint ineens aan het einde met een sprint.
[326.18 --> 327.18]  Waar je u tegen zegt.
[328.36 --> 330.20]  Ik had hem wel een beetje aanzien komen, denk ik.
[330.24 --> 331.52]  Als in ik ben niet helemaal verbaasd.
[331.52 --> 333.92]  Maar het is toch gek om ineens te voelen van...
[333.92 --> 335.98]  Maar nu hebben ze ineens allemaal interne teams.
[335.98 --> 338.00]  Op meerdere parallele projecten tegelijk zitten.
[338.20 --> 339.26]  Alles draait op Gemini.
[339.52 --> 341.92]  En ze hebben ook demos laten zien van Gemini en robotics.
[342.40 --> 344.36]  Er zijn heel veel dingen die je vanuit de wetenschap.
[344.44 --> 347.28]  Of vanuit wat er allemaal in de academische wereld rondom AI gebeurt.
[347.40 --> 348.26]  Kan voorzien.
[348.58 --> 349.96]  Want daar wordt dan geoefend met...
[349.96 --> 353.46]  Kunnen we zo'n taalmodel of zo'n multimodaal model ook gebruiken voor robotica.
[353.86 --> 354.68]  Maar dat duurt dan wel leven.
[354.74 --> 357.90]  Voor het dan ook daadwerkelijk hetzelfde Gemini model is.
[358.26 --> 359.24]  En dat Google ook zegt.
[359.34 --> 360.82]  Hier zijn tools voor ontwikkelaars.
[361.02 --> 363.16]  Waardoor jij robots kunt aansturen met Gemini.
[363.48 --> 366.56]  Hier zijn tools waarmee jij Gemini als coding assistant kan inzetten.
[366.56 --> 370.04]  Allemaal losse projecten.
[370.06 --> 371.56]  Maar allemaal draaiende op datzelfde basismodel.
[372.58 --> 374.56]  En dat is wel een grote denk ik dat...
[375.32 --> 379.80]  Dat nu toch een soort van explosie is van het toepassen van het grote Gemini.
[380.00 --> 380.56]  Ja, oké.
[381.20 --> 382.88]  Dat snap ik in abstracto.
[383.08 --> 387.56]  Maar moet je dan zeggen dit valt uit elkaar in die projecten die ik net genoemd heb?
[387.58 --> 388.80]  Ja, en ik denk dat je daardoor ook...
[388.80 --> 391.56]  Want in essentie het succes van Notebook LM.
[391.76 --> 393.58]  Wat een team binnen Google was.
[393.58 --> 397.86]  Is die een soort van oude Google X-achtige dingen mocht doen.
[398.04 --> 401.32]  Ga maar lekker los en maak wat zinvols voor iemand die iets met onderzoek wil doen.
[402.08 --> 404.46]  Dat er nu allerlei projecten naast elkaar lopen.
[404.58 --> 406.30]  Onder al die coole namen die je net hebt genoemd.
[406.72 --> 407.54]  Welke weet je het vetste?
[407.84 --> 409.32]  Laten we er gewoon induiken.
[410.16 --> 414.42]  Ja, ik ben nu het meest onder de indruk van hun advanced audio.
[414.54 --> 414.96]  Hoe noemen ze het?
[414.96 --> 416.54]  Het heeft een hele lange complexe naam volgens mij.
[416.62 --> 417.30]  Ik weet het eigenlijk niet eens.
[417.38 --> 420.68]  Maar goed, het is eigenlijk wat we zo gaaf vinden aan Notebook LM.
[420.68 --> 423.20]  De kuchjes, de lachjes, de emotie vooral.
[423.58 --> 426.60]  Je bedoelt het podcast laten genereren door Notebook LM.
[426.68 --> 428.14]  Op het moment je een pdf uploads.
[428.26 --> 429.84]  Dan kan dat ding daar een podcast van maken.
[429.90 --> 432.38]  Tussen twee hosts die heel natuurlijk praten.
[432.52 --> 434.42]  En inderdaad kuchjes en pauzes laten vallen.
[434.62 --> 437.36]  Ja, waar ik me als ontwikkelaar al langer...
[437.36 --> 438.54]  Nou, is het frustratie?
[438.60 --> 440.00]  Ja, want ik ben gewoon heel erg ongeduldig.
[440.58 --> 443.96]  Ik zat te wachten op een soort dik gedrukt cursief en underline.
[444.08 --> 445.78]  Zoals je dat normaal in een word processor kan.
[445.90 --> 447.70]  Dingen dik maken, dingen cursief maken.
[447.70 --> 450.52]  Dat wilde ik voor tekst en dan voor emotie.
[451.22 --> 451.78]  In audio.
[452.06 --> 453.58]  Ja, dat Google tegen mij zou zeggen...
[453.58 --> 456.34]  Als jij een ster, sterretjes om een woord heen zet...
[456.34 --> 458.92]  Dan gaat die persoon die dat uitspreekt, die nep persoon...
[458.92 --> 460.92]  Die gaat even op een andere manier dat uitspreken.
[460.98 --> 463.54]  Want het moet misschien een woord zijn met extra nadruk.
[463.68 --> 464.32]  Zoals ik nu doe.
[464.54 --> 466.04]  Of even luisteren.
[466.04 --> 469.26]  En waarom wil je dit zo graag?
[469.90 --> 475.08]  Omdat de audio content die nu gegenereerd wordt door die modellen...
[475.08 --> 476.28]  Is toch heel erg monatoom.
[476.96 --> 480.10]  Er wordt een soort gegokt door het model aan de hand van het lezen.
[480.54 --> 481.78]  Waar moet ik nu nadruk leggen?
[482.02 --> 483.18]  Zie je het als een audiobook.
[483.52 --> 486.16]  Een goede voorleesstem die beseft ook...
[486.16 --> 488.24]  Ik moet hier even een pauze houden, want er komt een reveal.
[488.56 --> 489.72]  Wie staat er achter de deur?
[490.24 --> 490.68]  Alexander.
[491.16 --> 494.28]  En dat kan je al doen door die tekst te interpreteren.
[494.28 --> 496.96]  Maar nu kan jij als ontwikkelaar zeggen...
[496.96 --> 499.26]  Ik wil pauzes gewoon door puntjes toe te voegen.
[499.34 --> 500.42]  Het is allemaal helemaal niet zo ingewikkeld.
[500.90 --> 502.14]  Ik wil nadruk daarop.
[502.22 --> 503.90]  Ik wil dat je hier een soort...
[503.90 --> 505.94]  Net als sarcasm tags op internet zeg maar.
[506.28 --> 507.40]  Van weet je...
[507.40 --> 507.96]  Je gaat nu...
[507.96 --> 508.78]  Ze had een heel mooie demo.
[509.24 --> 509.96]  Ging over het weer.
[510.10 --> 510.74]  Dus dan...
[510.74 --> 513.04]  Het weer wordt iedere dag aan jou verteld via je smart speaker.
[513.38 --> 513.96]  Door een stem.
[514.34 --> 516.30]  En als het weer heel slecht is...
[516.30 --> 518.36]  Dan krijg je ook een soort van verdrietige stem.
[518.42 --> 518.96]  Die zegt van...
[518.96 --> 519.58]  Ah, het is weer...
[519.58 --> 520.34]  Dat is nu zo.
[520.44 --> 520.86]  Nee, toch?
[520.86 --> 521.56]  Dit is niet zo.
[521.64 --> 523.04]  Nu met een Google...
[523.04 --> 524.86]  Een soort van straakassistent.
[525.10 --> 525.84]  Laat ik zo zeggen...
[525.84 --> 527.16]  Kijk, als ontwikkelaar...
[527.16 --> 528.62]  Het is nu zo in mijn hoofd.
[528.76 --> 529.34]  Ja, oké.
[529.38 --> 532.46]  Maar als eind-eind gebruiker die een smart speaker heeft...
[532.46 --> 532.68]  Nee.
[533.16 --> 533.92]  Alleen...
[533.92 --> 536.80]  Voor iedere smart speaker maker in de wereld...
[536.80 --> 538.46]  En iedereen die iets met audio doet...
[538.46 --> 542.28]  Kan jij nu wel die emotie van die stem sturing geven.
[542.36 --> 544.00]  En ik vond dat wel het laatste puzzelstukje.
[544.08 --> 544.52]  Maar oké.
[544.56 --> 545.66]  Even resumerend.
[545.72 --> 548.92]  Want je zoomt nu in op een heel specifiek deel...
[548.92 --> 551.02]  Van dit enorme model.
[551.18 --> 552.22]  Ja, maar het is op zich...
[552.22 --> 553.94]  Denk ik ook wel exemplarisch.
[554.04 --> 556.48]  Want we duiken nu één vertical in.
[556.66 --> 558.42]  Namelijk spraak genereren.
[558.54 --> 560.22]  Met hetzelfde model dat ik plaatje kan maken.
[560.38 --> 561.92]  En we zullen dadelijk zien...
[561.92 --> 562.96]  Je computer kan bedienen.
[563.22 --> 565.46]  En de wereld om je heen kan begrijpen.
[565.56 --> 567.52]  Maar nu eerst even dit specifieke ding.
[567.58 --> 568.84]  Want dit vind jij het interessantst.
[569.76 --> 571.60]  Het genereren van stemmen...
[571.60 --> 574.26]  Was een paar jaar geleden nog een robotstem.
[574.86 --> 577.34]  Dat is met Eleven Labs allemaal natuurlijker geworden.
[577.46 --> 579.12]  Dat is veel natuurlijker taal geworden.
[579.42 --> 580.78]  En hij kan ook accenten doen.
[581.24 --> 581.60]  En daarmee...
[582.16 --> 584.44]  Nou, daarmee hebben we echt al een soort van...
[584.44 --> 585.28]  Wow effect bereikt.
[585.42 --> 586.70]  Maar zeg jij...
[586.70 --> 587.90]  Je komt er eigenlijk achter...
[587.90 --> 590.02]  Door dit nu veel te gebruiken in de praktijk.
[590.14 --> 591.62]  Text to speech.
[591.94 --> 593.58]  Dat je zit te luisteren naar artikelen of zo.
[593.58 --> 595.74]  Dat het nog steeds niet het haalt...
[595.74 --> 598.58]  Bij het ingesproken stemmen van bijvoorbeeld audiobooken.
[599.22 --> 599.86]  Door echte mensen.
[599.86 --> 601.96]  En dat komt door dit soort dingetjes.
[602.10 --> 604.46]  Die pauzes laten vallen of nadruk leggen.
[604.52 --> 604.96]  Dat soort dingen.
[605.62 --> 609.38]  En dat is iets wat AI kan proberen na te doen met Eleven Labs.
[609.48 --> 611.26]  Maar dat gaat vaak genoeg nog mis.
[611.32 --> 614.54]  Dat je alsnog een beetje vermoeid blijft om daarnaar te luisteren.
[614.62 --> 617.34]  Dat de klemtonen alsnog verkeerd gelegd worden.
[617.66 --> 619.52]  En wat jij nu zegt is...
[619.52 --> 623.74]  Nu kan je als programmeur zelf die elementen toevoegen.
[624.04 --> 624.40]  Programmeur.
[624.50 --> 625.36]  Je hoeft helemaal geen programmeur.
[625.50 --> 626.54]  Dat is een dombe noem.
[626.54 --> 628.14]  Nee, het is gewoon tekst.
[628.14 --> 631.58]  Ja, dan ga je luisteren naar wat dat ding genereert.
[631.66 --> 631.98]  En dan denk je...
[631.98 --> 633.26]  Eigenlijk moet je hier een pauze laten vallen.
[633.38 --> 635.18]  En dan kun je die zelf toevoegen.
[635.36 --> 638.30]  En daarmee kun je eigenlijk die magie van Notebook LM...
[638.30 --> 642.20]  Die podcast die die Google tool voor je genereert...
[642.20 --> 644.34]  Kun je eigenlijk meer controle overnemen.
[644.60 --> 646.98]  Door zelf zo'n tekst te verrijken.
[647.52 --> 649.74]  En misschien te prompten op zo'n manier...
[649.74 --> 652.00]  Dat het op schaal gaat werken.
[652.06 --> 653.14]  En dat het geloofwaardiger wordt.
[653.14 --> 657.90]  Ja, het is echt alsof je van een lijntekening naar inkleuren.
[658.24 --> 660.46]  We kunnen nu eindelijk emoties inkleuren op het tekst.
[660.46 --> 661.06]  Instemmen.
[661.50 --> 661.90]  Instemmen.
[662.02 --> 662.98]  En ik denk dat...
[662.98 --> 664.02]  En ik kan me zo voorstellen...
[664.02 --> 665.94]  Ik zit nu, terwijl we het hier over hebben te denken...
[665.94 --> 667.34]  Dan gooi ik er een tekst in.
[667.66 --> 668.28]  Een stuk audio.
[669.04 --> 669.72]  Wilfried de Jong.
[670.28 --> 670.76]  Rotterdammer.
[671.68 --> 673.72]  Rotterdammers die praten namelijk anders dan Amerikanen.
[674.06 --> 675.68]  Zeker Amerikanen uit de stad.
[676.08 --> 676.74]  Ja, dat is ook.
[676.84 --> 677.86]  Want nu hebben we...
[677.86 --> 679.92]  Nu kunnen we het zeg maar emotioneel inkleuren.
[679.92 --> 683.18]  Maar ik vind die Notebook LM podcast die gemaakt worden...
[683.18 --> 684.56]  Ook niet zo chill om naar te luisteren.
[684.64 --> 685.24]  Want ik ben...
[685.24 --> 688.60]  Ik kan best wel wat hebben van die soort van frivoliteit van Amerikanen.
[688.64 --> 689.78]  Maar niet te veel op één dag.
[689.92 --> 692.28]  Ja, ze zijn wel heel enthousiast over alles.
[692.30 --> 692.98]  Echt over niks.
[693.06 --> 694.36]  Dat is wel echt...
[694.36 --> 695.92]  Daar word je op een gegeven moment heel vermoeid van.
[696.08 --> 697.78]  Ja, dus ik zou dan denk ik...
[697.78 --> 700.92]  Misschien wil ik dan een soort van de kleur...
[701.78 --> 705.28]  Taal, emotie kleur pakken uit een fragment van Wilfried de Jong.
[705.38 --> 706.76]  Dat dan omzetten in syntax.
[706.76 --> 707.96]  Dat is echt super developer dit.
[707.96 --> 710.06]  Maar zodat ik dat mee kan geven in de prompt.
[710.16 --> 711.22]  En kan zeggen oké, luister.
[711.38 --> 712.78]  Ik zou dat dan klaut vragen denk ik nog.
[712.98 --> 714.00]  Ik heb eigenlijk nog niet...
[714.00 --> 715.82]  De vraag hoe praat Wilfried de Jong.
[715.92 --> 719.08]  En dat wil je dan uitgelegd krijgen in waar die pauzes laat vallen bijvoorbeeld.
[719.36 --> 723.22]  Ja, en dan ook zeggen joh, er is nu voor mij een mogelijkheid om...
[723.22 --> 726.34]  Je gaat voor mij een tekst maken die ik straks in een taalmodel ga stoppen.
[726.44 --> 728.96]  Die de mogelijkheid heeft om aan te geven wat benadrukt moet worden.
[729.06 --> 730.30]  Wat verdrietig verteld wordt, et cetera.
[730.46 --> 731.94]  Daar mag je deze syntax voor gebruiken.
[732.06 --> 733.60]  Hop, documentatie van Gemini erin.
[733.60 --> 735.96]  En dan wil ik speech to text doen.
[736.08 --> 740.56]  Dus een bestaande ding zodat ik mezelf kan laten inspireren.
[740.68 --> 745.20]  En een soort van mimicking kan doen van iemands manier van emotie geven in taal.
[745.64 --> 746.80]  Dat omzetten in tekst.
[747.12 --> 749.24]  En dan die tekst aanvullen met de juiste codes.
[749.42 --> 750.88]  Om daar een podcast uit te maken.
[751.00 --> 751.98]  Of wat dan ook eigenlijk.
[752.38 --> 756.38]  Met als het ware een Rotterdammer wat betreft emotionele kleur in tekst.
[756.38 --> 759.46]  gemaakt door Gemini met die audio.
[759.64 --> 761.24]  Want ik denk wat mij betreft.
[761.34 --> 764.24]  Ik stuurde een aantal mensen vanochtend toen ik dit las.
[764.42 --> 765.44]  Van die Gemini feature.
[765.84 --> 768.44]  Van dit was voor mij het laatste puzzelstukje.
[768.88 --> 770.78]  Wat betreft audio is het nu klaar.
[771.74 --> 772.02]  Ja.
[772.50 --> 773.72]  En dit is belangrijk.
[773.92 --> 778.86]  Omdat denk ik mensen die met spraakassistenten spreken.
[779.08 --> 780.36]  Dat doen we allemaal wel eens met Siri.
[780.68 --> 782.86]  Dan is er een niveau waarop je geïrriteerd bent.
[782.86 --> 784.84]  Dat het ding gewoon niet begrijpt waar je het over hebt.
[784.84 --> 788.26]  Dat is één ding wat je beslechten moet.
[788.38 --> 792.28]  En dat is al een stuk beter geworden door de introductie van generatieve AI.
[792.42 --> 793.50]  In die spraakassistenten.
[793.56 --> 795.14]  Hiervoor was het een beetje een soort van.
[795.32 --> 796.98]  Als de gebruiker vraagt om een timer.
[797.18 --> 798.06]  Dan zet je een timer.
[798.80 --> 801.12]  Nu kan je het op alle mogelijke manieren.
[801.30 --> 801.74]  Kun je het vragen.
[801.84 --> 802.88]  Begrijpt hij het nog steeds.
[803.14 --> 805.84]  En kan je veel ingewikkeldere vragen stellen aan dat ding.
[806.46 --> 808.28]  Dat is één niveau waarop dingen beslecht worden.
[809.22 --> 809.82]  Maar alsnog.
[809.82 --> 813.28]  Als je dan bijvoorbeeld chatty advanced voice mode gebruikt.
[813.28 --> 815.38]  Die stem die je kan onderbreken.
[815.56 --> 816.64]  Die lage latency heeft.
[816.72 --> 818.02]  Waardoor er weinig pauze valt.
[818.16 --> 819.08]  En veel vragen kan stellen.
[819.22 --> 821.02]  En ook wel een beetje emotie heeft.
[821.70 --> 823.20]  Alsnog merk ik.
[823.58 --> 824.96]  Als gebruiker.
[825.66 --> 827.76]  Dat het vermoeiend is om met dat ding te blijven praten.
[828.14 --> 830.60]  Omdat dit element waar jij het nu over hebt.
[830.68 --> 831.44]  Nog niet goed werkt.
[831.58 --> 831.82]  Klopt.
[831.94 --> 834.36]  En ik merk zelfs dat in die uncanny valley.
[834.58 --> 835.62]  Dus het tussenstuk tussen.
[836.08 --> 836.74]  Het is meh.
[836.74 --> 838.28]  Het gaat nu richting bijna echt.
[838.46 --> 839.36]  En dat stapje ertussen.
[839.36 --> 842.48]  Is een best wel frustrerende plek om te zijn als gebruiker.
[842.88 --> 844.40]  Want ik merk nu dat ik nog liever heb.
[844.46 --> 847.18]  Dat ik een lichtknopje in mijn kamer niet kan indrukken.
[847.58 --> 850.20]  Dan dat ik met mijn vinger tot één centimeter voor dat knopje kom.
[850.24 --> 851.64]  En in de lucht blijf vastzitten.
[852.12 --> 852.34]  Snap je.
[852.38 --> 853.96]  Het frustreert mij als gebruiker.
[854.32 --> 856.28]  Dat ik drie procent af ben van mijn doel.
[856.46 --> 858.58]  Ik ben dan liever denk ik vijftig procent af van mijn doel.
[858.80 --> 858.90]  Ja.
[859.02 --> 860.48]  En ik ben nu aan het praten met die dingen.
[860.58 --> 861.48]  We zijn zo dichtbij.
[861.48 --> 866.34]  En nog steeds voelt het niet als iets wat je daadwerkelijk als alternatief voor een vriend bellen.
[866.40 --> 867.28]  Is het gewoon niet.
[867.70 --> 868.40]  En dan snap ik.
[868.56 --> 869.10]  Ik bedoel dat niet.
[869.22 --> 870.14]  Je hebt geen vrienden meer nodig.
[870.24 --> 871.06]  Dat hele ding.
[871.16 --> 871.36]  Maar gewoon.
[871.82 --> 873.46]  Zoals je met een vriend praat.
[873.78 --> 877.18]  Daar komt dat ding nog steeds niet dichtbij genoeg.
[877.28 --> 880.26]  Om dat gewoon een fietstochtje lang met Chachipati te gaan praten.
[880.40 --> 880.68]  Bijvoorbeeld.
[881.62 --> 883.22]  En dit is dus wat jij zegt.
[883.48 --> 884.46]  Om hier te komen.
[884.58 --> 885.96]  Om hier dichterbij te komen.
[886.44 --> 887.14]  Dat is nodig.
[887.40 --> 889.28]  Om het echt in ons leven te verwerken.
[889.28 --> 890.94]  En dat je ook echt met je computer gaat praten.
[891.02 --> 892.24]  Zoals wij dat de hele tijd voorspellen.
[892.48 --> 894.44]  De sci-fi movie die wij de hele tijd schetsen.
[895.82 --> 897.54]  Om dat daadwerkelijk te komen.
[897.78 --> 899.94]  Moet dat stemdeel goed werken.
[900.24 --> 901.18]  Daarvoor heb je die emoties nodig.
[901.20 --> 901.44]  Exact.
[901.60 --> 903.04]  En als je dan nog even terug op die film.
[903.14 --> 903.38]  Her.
[903.48 --> 904.58]  Waar we het vaak over hebben gehad.
[904.68 --> 905.82]  Met Scarlett Johansson erin.
[906.28 --> 907.94]  Man wordt verliefd op een AI.
[908.28 --> 908.60]  OS.
[908.74 --> 909.84]  Zoals het dan in die film nog heette.
[910.56 --> 911.78]  Daar zijn wel checkboxes.
[912.16 --> 913.02]  Wat mij betreft.
[913.32 --> 913.48]  Ja.
[913.70 --> 915.86]  Is dat audio ding nu echt klaar.
[915.96 --> 916.04]  Ja.
[916.04 --> 917.10]  En dat vind ik best wel groot.
[917.26 --> 917.40]  Ja.
[917.72 --> 918.92]  Voor wat ik ervan gezien heb.
[918.92 --> 920.40]  Los van het feit dat de video.
[920.84 --> 921.90]  Waar het in uitgelegd wordt.
[922.38 --> 923.00]  Gevoiced wordt.
[923.40 --> 924.22]  Door het systeem zelf.
[924.52 --> 924.68]  Ja.
[924.74 --> 927.38]  En echt zonder enige vorm van irritatie aan mijn kant.
[927.46 --> 927.56]  Ja.
[927.56 --> 928.98]  Je hebt het nu over een video die Google.
[929.14 --> 930.00]  Het is heel erg meta dit.
[930.16 --> 930.34]  Ja.
[930.56 --> 931.40]  Maar ik doe wel even.
[931.52 --> 931.82]  Dankjewel.
[931.88 --> 932.46]  Ik betaal het wel even.
[932.86 --> 933.46]  Dit is een video.
[933.60 --> 934.86]  Dit is een hele reeks met video's.
[934.90 --> 936.18]  Die Google online heeft gezet.
[936.28 --> 936.66]  Waarin ze.
[936.92 --> 937.18]  Nou ja.
[937.82 --> 938.70]  Specifieke delen.
[938.92 --> 940.34]  Van een heel groot verhaal.
[940.60 --> 940.94]  Nogmaals.
[941.00 --> 942.40]  Dit is een heel klein dingetje.
[942.44 --> 943.06]  Waar we nu inzoomen.
[943.20 --> 943.34]  Maar.
[944.04 --> 944.86]  Specifieke delen.
[944.86 --> 945.86]  Uitwerkt.
[945.94 --> 946.60]  En daar is onder andere.
[946.74 --> 948.38]  Dit soort van text to speech ding.
[948.50 --> 950.52]  Waar ze die notebook LM achtige stemmen.
[951.52 --> 951.88]  Gebruiken.
[952.20 --> 953.02]  In een video.
[953.26 --> 953.66]  Waar ze.
[954.02 --> 954.76]  Dat is een hele meta.
[955.00 --> 955.48]  Een video.
[955.64 --> 957.14]  Waarin ze dit ding uitleggen.
[957.22 --> 957.58]  En dat is gewoon.
[957.74 --> 958.36]  Heel echt.
[958.48 --> 959.60]  Dat zijn gewoon voice over stemmen.
[959.74 --> 961.16]  Die je op tv zou kunnen gebruiken.
[961.42 --> 961.54]  Ja.
[961.92 --> 962.40]  En daar.
[962.48 --> 963.06]  Daar zijn we nu.
[963.14 --> 963.44]  Oké.
[963.44 --> 964.92]  Dat is allemaal onderdeel.
[965.04 --> 967.20]  Van een groot nieuw model.
[967.42 --> 968.28]  Wat ze lanceren.
[968.34 --> 968.66]  Dat heet.
[968.80 --> 969.90]  Gemini 2.
[970.98 --> 971.92]  En het model.
[972.04 --> 972.94]  Wat ze dan concreet.
[973.06 --> 973.22]  Dat is.
[973.30 --> 974.48]  Dat wordt de paraplu.
[974.90 --> 977.22]  Daar komen verschillende submodellen onder te hangen.
[977.30 --> 977.60]  En het model.
[977.66 --> 978.42]  Wat ze nu lanceren.
[978.60 --> 978.72]  Heet.
[978.84 --> 980.30]  Gemini 2.0 Flash.
[980.54 --> 980.94]  Dat is.
[981.50 --> 982.56]  Flash is het model.
[982.68 --> 983.74]  Waarbij Google altijd heeft gezegd.
[983.78 --> 985.36]  Dat is ons kleinste model.
[985.70 --> 985.82]  Ja.
[987.14 --> 987.54]  Oftewel.
[987.86 --> 989.50]  Dit is het goedkoopste model.
[989.62 --> 990.22]  Om te draaien.
[990.36 --> 991.74]  Van deze 2.0 reeks.
[991.74 --> 993.60]  Waarvan dit nu de enige is.
[993.66 --> 994.00]  Die uitkomt.
[994.10 --> 994.80]  Maar dat impliceert.
[994.90 --> 996.98]  Dat er dus andere modellen ook zijn.
[997.14 --> 998.30]  Die niet geoptimaliseerd zijn.
[998.44 --> 999.06]  Voor klein.
[999.48 --> 999.72]  Snel.
[1000.00 --> 1000.44]  Goedkoop.
[1000.60 --> 1000.68]  Ja.
[1000.72 --> 1001.62]  Die snel is ook belangrijk.
[1001.78 --> 1002.72]  Want Flash is natuurlijk.
[1003.20 --> 1004.50]  Het is en een enorme flex.
[1004.58 --> 1005.06]  Vanuit Google.
[1005.16 --> 1006.22]  Dat ze hun Flash model.
[1006.38 --> 1007.06]  Als eerst uitbrengen.
[1007.12 --> 1008.08]  Die al zo krachtig is.
[1008.20 --> 1008.92]  Dat wij allemaal denken.
[1009.02 --> 1009.30]  Wauw.
[1009.56 --> 1011.10]  Maar je hebt ook een heel klein modelletje nodig.
[1011.10 --> 1012.34]  Voor die hele lage latency.
[1012.82 --> 1012.94]  Ja.
[1013.06 --> 1013.74]  Voor dat kletsen.
[1014.00 --> 1014.12]  Ja.
[1014.28 --> 1015.74]  Dat moet je met een turboachtig ding doen.
[1015.76 --> 1017.86]  Maar ondertussen is het dus een monster model.
[1018.12 --> 1018.92]  Want het Flash model.
[1018.92 --> 1020.88]  Wat we associëren.
[1020.88 --> 1021.96]  Met dus een kleiner model.
[1022.12 --> 1024.18]  Wat geoptimaliseerd is.
[1024.36 --> 1025.20]  Voor snelheid.
[1025.32 --> 1026.24]  En voor goedkoop.
[1026.44 --> 1028.44]  En waarbij de meeste mensen de neiging zou hebben.
[1028.54 --> 1029.00]  Nou oké.
[1029.04 --> 1030.60]  Dat ga ik niet voor de meeste taken gebruiken.
[1031.26 --> 1032.14]  Lijkt het dus.
[1032.46 --> 1034.00]  Dicht buiten scoren op benchmarks.
[1035.12 --> 1036.52]  Bij bijvoorbeeld.
[1036.94 --> 1038.12]  Cloud 3,5 Sonnet.
[1038.92 --> 1040.32]  Dat het dichtbij komt.
[1040.38 --> 1042.20]  En dat het soms beter zelfs werkt.
[1042.32 --> 1044.84]  Dan het midden model van Anthropic.
[1045.08 --> 1045.60]  Op dit moment.
[1045.74 --> 1045.98]  Zeker.
[1046.68 --> 1047.56]  Dat is opvallend.
[1047.56 --> 1049.74]  Want daarnaast is dit veel goedkoper.
[1049.74 --> 1051.62]  Je vertelt het even casual.
[1051.86 --> 1052.30]  Maar eigenlijk.
[1052.60 --> 1053.24]  Ik zit denk ik ook.
[1053.24 --> 1053.62]  Het is huge.
[1053.82 --> 1053.98]  Ja.
[1054.04 --> 1056.46]  En ik zit denk ik misschien een beetje te wachten op Orion van OpenAI.
[1056.70 --> 1057.02]  Waardoor.
[1057.26 --> 1058.96]  Als Google dan ineens Gemini 2 dropt.
[1059.04 --> 1060.72]  Waarvan hun allerkleinste model in de buurt komt.
[1060.80 --> 1061.96]  Van Cloud 3,5 Sonnet.
[1062.02 --> 1063.84]  Die al ongeveer 30 procent beter voelt.
[1064.04 --> 1064.78]  Als GPT-4.
[1064.98 --> 1065.96]  Dan hebben we ineens.
[1066.80 --> 1067.98]  En dat is denk ik ook wat ik bedoel.
[1068.04 --> 1069.14]  Met die hardloopwedstrijd.
[1069.60 --> 1072.48]  Dit is wel echt een enorme positieve.
[1072.48 --> 1077.32]  Als je het prettig vindt dat de markt een beetje verdeeld is over verschillende spelers.
[1077.40 --> 1078.92]  Die redelijk met elkaar kunnen boksen.
[1079.64 --> 1081.62]  Dan Google is helemaal in the game nu.
[1081.94 --> 1082.42]  Maar goed.
[1082.46 --> 1084.48]  We hebben het nu alweer waar ik onder de indruk van ben.
[1084.60 --> 1086.56]  Waar ben jij van onder de indruk in dit Gemini launch?
[1086.74 --> 1086.90]  Nou.
[1087.00 --> 1088.70]  Eén ding wat je kan proberen.
[1088.82 --> 1090.22]  Want dat is natuurlijk waar het echt leuk wordt.
[1090.30 --> 1091.36]  Als je het zelf kan proberen.
[1091.44 --> 1093.40]  Want het is één ding om naar YouTube video's te kijken van dingen.
[1093.40 --> 1096.78]  Maar het is ook wel echt leuk dat Google daadwerkelijk dingen heeft gereleased.
[1096.86 --> 1097.52]  Die je kan proberen.
[1097.52 --> 1101.56]  Je kan dus naar AI studio.google.com gaan.
[1101.68 --> 1109.68]  En dat is de plek waar je de nieuwe features uit dit Gemini 2 Flash model kan proberen.
[1109.82 --> 1111.86]  En dat zijn allemaal heel beeldende dingen die je kan doen.
[1111.98 --> 1116.82]  Dus bijvoorbeeld je kan je scherm delen met Gemini.
[1117.24 --> 1121.42]  En dan kun je dus dat ding spreken met je stem.
[1121.96 --> 1124.86]  Terwijl dat ding ook toegang heeft tot je scherm.
[1124.86 --> 1127.92]  Dus je kan vragen stellen over hetgeen je op dat moment ziet.
[1128.38 --> 1129.00]  Dus ik zal dat doen.
[1129.08 --> 1131.80]  Ik ga nu één venster delen.
[1131.92 --> 1132.92]  Namelijk dat van mijn browser.
[1133.08 --> 1134.64]  Can you see this, dear Gemini?
[1136.52 --> 1138.56]  Yes, I can see the browser window you are sharing.
[1138.76 --> 1141.20]  It appears to be the Google AI studio page.
[1141.22 --> 1143.88]  Ja, well that you are very right.
[1143.98 --> 1145.60]  Oké, I now go to nude.nl.
[1145.68 --> 1147.54]  This is a very big news site in Nederland.
[1148.40 --> 1151.42]  What do you think is going on today in the news?
[1151.42 --> 1156.92]  Oké, I can see the NU, NL website you've shared.
[1157.48 --> 1159.40]  It appears to be a Dutch news site.
[1159.70 --> 1160.90]  And I can see a few headlines.
[1161.56 --> 1166.22]  One headline mentions a fourth suspect being arrested in connection with an explosion.
[1166.80 --> 1170.28]  There are also articles about measures to reduce working hours.
[1170.34 --> 1174.08]  Oké, what's the most fun story that is on this page?
[1174.08 --> 1177.86]  Sure, the headline.
[1178.30 --> 1181.18]  Miss Nederland verkiezing stopt na 35 jaar.
[1181.60 --> 1183.22]  Niet meer van deze tijd.
[1183.64 --> 1187.92]  Which translates to Miss Nederland's pageant stops after 35 years.
[1188.24 --> 1189.38]  No longer of this time.
[1189.80 --> 1191.36]  Seems like it could be an interesting story.
[1191.72 --> 1192.30]  Ja, oké.
[1192.34 --> 1193.46]  Nou, dat moet je zelf weten.
[1193.90 --> 1199.44]  Maar dit is dus het idee dat je naar een website kan kijken en dan met dat ding erover kan praten.
[1199.64 --> 1200.82]  Nou, dit is een beetje een dom voorbeeld.
[1200.82 --> 1207.82]  Maar ik heb bijvoorbeeld ook news.cn, dat is de website van het staatspersbureau in China.
[1208.54 --> 1212.04]  Can you describe what's on this page right now?
[1214.04 --> 1216.42]  I see a Chinese news website, news.
[1217.10 --> 1217.86]  CNN.
[1218.74 --> 1220.86]  The page has a header with links and icons.
[1221.26 --> 1224.36]  Then below there is a large image of Xi Jinping, the Chinese president.
[1224.70 --> 1224.82]  Typical.
[1224.82 --> 1226.82]  The page also features several head...
[1227.42 --> 1230.02]  Sorry, there was some commentary, some political commentary.
[1230.02 --> 1232.18]  In ieder geval, dat is natuurlijk wel grappig.
[1232.30 --> 1235.14]  Ik zit nu naar een pagina te kijken waar ik werkelijk geen wijsheid kan worden.
[1235.24 --> 1236.74]  Behalve een hele grote van Xi Jinping.
[1237.24 --> 1238.96]  Bovenal de nieuws site.
[1239.42 --> 1242.44]  Maar verder is het alleen maar karakters die ik niet kan lezen.
[1242.90 --> 1245.22]  En het feit dat dat ding kan, dat wel.
[1245.32 --> 1246.02]  Dus dat is grappig.
[1247.18 --> 1250.26]  Can you maybe teach me some Chinese based on what this says?
[1250.40 --> 1253.66]  Can you pronounce the top headline and say it in Chinese?
[1253.66 --> 1254.66]  Yes.
[1256.66 --> 1258.66]  The top headline reads...
[1259.38 --> 1264.66]  The pronunciation is...
[1264.66 --> 1270.98]  Xi Jinping huijian eluosi tongyi eluosi dangzooksi mei de vejjefu.
[1273.58 --> 1274.04]  Oké.
[1274.04 --> 1275.10]  En wat betekent dat?
[1278.28 --> 1279.66]  It translates to...
[1279.66 --> 1282.42]  Xi Jinping meets with the chairman of the United Russia party.
[1282.42 --> 1283.18]  Met vet-ev.
[1283.44 --> 1283.62]  Ja.
[1283.84 --> 1284.40]  Ja, oké.
[1284.48 --> 1286.54]  Zo zie je dus dat je ook Engels en Nederlands door elkaar kan praten.
[1286.54 --> 1287.18]  Ja, ik wou net zeggen.
[1287.18 --> 1287.66]  Dat is wel chill.
[1287.90 --> 1290.58]  Een bizarre flex met alle talen door elkaar op dit moment.
[1291.06 --> 1291.40]  Oké.
[1291.44 --> 1294.40]  Nou, een ander ding is dat ik de YouTube homepage kan laten zien.
[1294.62 --> 1299.62]  Die heeft natuurlijk allerlei video's die die aanbeveelt op basis van mijn kijkgedrag.
[1299.62 --> 1303.62]  Dus mijn vraag aan jou is, wat zou je zeggen dat...
[1304.28 --> 1306.52]  Zeg maar, wat zou je zeggen over mijn persoonlijkheid?
[1306.60 --> 1310.96]  Hoe kan je mijn karakter schetsen op basis van de video die YouTube voor mij heeft uitgekozen?
[1311.06 --> 1312.52]  Die nu voor mij staan op het scherm.
[1312.62 --> 1313.46]  Wat voor mens ben ik?
[1313.46 --> 1316.46]  Oké.
[1316.46 --> 1316.54]  Oké.
[1316.54 --> 1323.28]  Based on the videos on your YouTube homepage, it seems you might be interested in technology, AI, news, and interviews.
[1323.86 --> 1327.38]  The videos are diverse, but they all seem to fall into those main categories.
[1328.82 --> 1329.06]  Oké.
[1329.12 --> 1330.22]  Welke moet ik kijken als eerste?
[1333.10 --> 1340.20]  Of those videos, my local AI voice assistant, I replaced Alexa, seems like an interesting one to start with.
[1342.20 --> 1342.64]  Oké.
[1342.88 --> 1343.36]  Bedankt.
[1343.46 --> 1348.14]  Ik kan me echt oprecht goed voorstellen.
[1348.26 --> 1348.92]  Je ziet het ook een beetje.
[1349.06 --> 1352.44]  Er zit namelijk in Gemini nu ook, Gemini Gaming.
[1352.72 --> 1353.20]  Waarom niet?
[1353.28 --> 1354.66]  Hebben we het nog niet eens over gehad, dit lijstje.
[1354.74 --> 1357.16]  Maar ook geoptimaliseerd voor computer games.
[1357.66 --> 1361.26]  Waarbij je een buddy kan hebben die meekijkt op jouw scherm op dezezelfde manier.
[1361.36 --> 1363.26]  Maar niet naar een webbrowser, maar naar een computer game.
[1363.72 --> 1365.94]  En dat jij dan zegt, ik zit nu in deze strategie game.
[1366.02 --> 1367.36]  Wat is mijn beste volgende move?
[1367.60 --> 1372.04]  Dan heb ik het niet over volgende move schaken, maar best wel een complexe spelsituatie.
[1372.04 --> 1374.22]  Het is ook een vorm van cheater zou je kunnen zeggen.
[1374.54 --> 1376.72]  Maar het kan ook een vorm van leren zijn.
[1376.92 --> 1381.20]  Want wat ik iemand zag doen, die ging code samen met Gemini die meekeek.
[1381.20 --> 1383.60]  En toen zei hij, oké, wat zie je nu?
[1383.68 --> 1384.50]  Ik zie een code editor.
[1385.12 --> 1387.92]  Oké, stel dat ik nu hallo naar mezelf zou willen zeggen.
[1388.00 --> 1388.66]  Hoe doe ik dat dan?
[1388.72 --> 1391.32]  En dan ging hij dus in voice zeggen, oké, dan moet je typen.
[1391.54 --> 1391.86]  Print.
[1392.08 --> 1393.52]  En daar ging hij helemaal mee typen.
[1393.62 --> 1394.74]  En ik dacht, zo frustreerend.
[1394.82 --> 1396.16]  Maar ik dacht, zo leer je het wel.
[1396.56 --> 1398.46]  En toen vroeg hij, heb ik het goed neergezet?
[1398.70 --> 1399.64]  Ja, je hebt het goed getypt.
[1399.80 --> 1400.40]  Voer het maar naar huis.
[1400.74 --> 1403.06]  Toen dacht ik, dit is veel meer die buddy.
[1403.40 --> 1405.18]  In plaats van dat plakken uit je klembord.
[1405.30 --> 1405.50]  Precies.
[1405.66 --> 1406.92]  Er wordt niet voor je getypt.
[1407.08 --> 1408.64]  Er wordt je uitgelegd.
[1408.64 --> 1410.54]  Maar je moet zelf de fitness oefening doen.
[1410.66 --> 1411.88]  Zodat je zelf spiermassa creëert.
[1412.18 --> 1415.24]  Ja, en dit is het voorportaal van wat ze noemen Project Astra.
[1415.48 --> 1419.28]  Dat is dus die persoonlijke assistent die meerdere talen door elkaar heen spreekt.
[1419.46 --> 1420.42]  Zoals je net hoorde.
[1421.02 --> 1424.26]  En die ook begrijpt wat dat ding ziet.
[1424.46 --> 1428.50]  Nu delen wij ons scherm met Gemini.
[1429.06 --> 1433.00]  En kan je dus op basis van video in plaats van screenshots, wat we van Chattieptie gewend zijn.
[1433.00 --> 1437.84]  Kun je op basis van live streaming video vanaf je scherm je helpen.
[1437.84 --> 1438.78]  Wat je aan het doen bent.
[1439.96 --> 1445.68]  Maar datzelfde, je kan natuurlijk in plaats van schermbeelden, kun je ook gewoon videobeelden naar het ding sturen.
[1445.78 --> 1446.74]  Dus je kan ook je webcam.
[1446.92 --> 1450.06]  Als jij dingen wil laten zien voor het scherm.
[1450.60 --> 1452.76]  Bijvoorbeeld een rekensom die je op een papiertje hebt geschreven.
[1453.44 --> 1454.74]  Kan je dat live fixen.
[1455.00 --> 1457.02]  Dat doet OpenAI niet live.
[1457.14 --> 1459.52]  Dat is bij OpenAI nog een soort van demo territory.
[1459.76 --> 1460.90]  En bij Google is het nu live.
[1460.90 --> 1463.14]  Dat is een simpel voorbeeld.
[1463.52 --> 1469.52]  Maar waar ze het dus ook voor gebruiken is dat je live camerabeeld van je telefoon kan streamen naar dat ding.
[1469.68 --> 1471.66]  Dat is technisch natuurlijk precies hetzelfde.
[1472.10 --> 1473.64]  En kun je vragen over je omgeving.
[1473.80 --> 1478.40]  En dan zit het vol met allerlei voorbeelden van zogenaamde trusted testers.
[1478.62 --> 1479.80]  Zoals Google dat tegenwoordig noemt.
[1479.88 --> 1482.70]  Een soort van beta testers die ook influencers zijn volgens mij.
[1482.70 --> 1485.86]  Die dan bijvoorbeeld door een keuken lopen.
[1486.02 --> 1490.52]  En dan een reeks met ingrediënten in hun kastje hebben staan.
[1490.70 --> 1493.30]  En waarbij je dan de vraag kan stellen wat kan ik hiervan maken.
[1493.50 --> 1497.06]  Nou dat is een nog wel simpel voorbeeld.
[1497.84 --> 1501.16]  Wat een soort cliché matig voorbeeld van AI.
[1501.78 --> 1502.58]  Laten zien wat het kan.
[1502.90 --> 1503.60]  Maar oké.
[1503.68 --> 1504.28]  In video.
[1504.48 --> 1504.98]  Best wel vet.
[1505.66 --> 1507.24]  Maar dat gaat verder en verder.
[1507.24 --> 1512.74]  Want dan is het echt de beperkingen van je creativiteit zijn de grenzen aan wat je met dat ding kan doen.
[1512.98 --> 1514.28]  Want echt heel veel kan.
[1514.36 --> 1514.98]  Dus bijvoorbeeld.
[1515.56 --> 1518.80]  Je kan een videootje maken waarin je een boek voor je hebt.
[1518.92 --> 1520.66]  En waarbij je heel snel door het boek bladert.
[1521.50 --> 1522.92]  En dan heeft hij iedere pagina.
[1523.02 --> 1526.28]  Heeft hij maar natuurlijk een fractie van een seconde nodig om de pagina gelezen te hebben.
[1526.80 --> 1527.50]  En dan kun je zeggen.
[1528.42 --> 1533.44]  Nou dit laatste paar pagina's voordat ik dit boek neerlegde een jaar geleden.
[1533.98 --> 1536.92]  Praat me even bij over wat er ook weer gebeurd is.
[1536.92 --> 1538.50]  Ik weet dat ik hier gebleven ben.
[1538.62 --> 1541.40]  Maar wat staat er op deze twintig pagina's hiervoor.
[1541.50 --> 1542.92]  En dan gaat dat ding dus praten.
[1543.04 --> 1544.80]  Zonder dat je een videootje hebt hoeven maken.
[1544.96 --> 1547.50]  Dus gewoon live streamen naar een spraakassistent.
[1548.00 --> 1550.78]  Die een audio naar je toe spreekt.
[1551.30 --> 1552.48]  Andere features waren.
[1553.06 --> 1554.64]  Die ik in video's voorbij zag komen.
[1554.90 --> 1560.18]  Was bijvoorbeeld iemand die met zijn telefoon over straat loopt.
[1560.50 --> 1562.72]  Random naar dingen aan het wijzen is.
[1562.72 --> 1564.16]  En dan vraagt wat is dit voor plant.
[1564.26 --> 1565.40]  Wat is dit voor gebouw.
[1565.76 --> 1566.84]  Wat is dit voor deelfiets.
[1566.84 --> 1567.60]  Die hier staat.
[1567.90 --> 1568.88]  En dan kan hij dus vragen.
[1569.10 --> 1571.20]  Wat zijn eigenlijk de voorwaarden van deze deelfiets.
[1571.26 --> 1572.82]  En zegt nou het kost x euro per maand.
[1573.00 --> 1574.38]  En je kunt het hier en hier gebruiken.
[1574.64 --> 1576.28]  Of hij wijst naar een bus.
[1576.60 --> 1577.40]  Met zijn camera.
[1577.62 --> 1578.80]  Die langs rijdt.
[1578.82 --> 1580.70]  En vraagt waar gaat deze bus heen.
[1581.04 --> 1584.02]  En dat ding constateert wat er voor op de bus staat.
[1584.16 --> 1584.98]  En het lijnnummer.
[1585.18 --> 1587.88]  Zoekt dan op welke buslijn dat is.
[1588.26 --> 1589.00]  En vraagt dan.
[1589.42 --> 1591.14]  Die persoon.
[1591.14 --> 1591.58]  Die mens.
[1591.58 --> 1593.34]  Die vraagt dan aan die AI.
[1593.78 --> 1595.46]  Wat zijn leuke dingen om.
[1596.12 --> 1598.22]  Als toeristische dingen om te zien.
[1598.22 --> 1599.94]  Als je deze bus neemt.
[1600.32 --> 1600.88]  En dan komt hij dus.
[1600.92 --> 1602.44]  Dan heeft hij dus op Google Maps opgezocht.
[1602.52 --> 1603.58]  Hoe die buslijn gaat.
[1603.78 --> 1605.90]  Welke dingen allemaal langs de kant van de weg staan.
[1606.00 --> 1606.78]  En gaat hij dus vertellen.
[1606.86 --> 1608.68]  Wat je allemaal op die bus kan zien.
[1608.68 --> 1609.22]  Oftewel.
[1609.80 --> 1610.84]  Hij kan niet alleen.
[1611.62 --> 1613.10]  Analyseren wat op het beeld te zien is.
[1613.18 --> 1615.26]  Hij kan ook nog dingen gaan opzoeken.
[1615.54 --> 1616.58]  En dan ook nog.
[1616.80 --> 1617.96]  Over verschillende apparaten.
[1618.04 --> 1618.90]  Want als jij en.
[1619.42 --> 1621.16]  Je telefoon camera gebruikt.
[1621.34 --> 1623.62]  Maar je geeft ook je telefoonscherm.
[1624.02 --> 1625.34]  Toegang aan dat ding.
[1626.12 --> 1626.52]  Tegelijkertijd.
[1627.08 --> 1627.74]  Kun je dus.
[1628.10 --> 1629.08]  Bijvoorbeeld vragen.
[1630.46 --> 1633.68]  Wat is de code van mijn Airbnb.
[1634.44 --> 1636.74]  Dan heeft hij die e-mail gezien op het scherm.
[1636.86 --> 1638.32]  Dus het is niet dat hij in je Gmail gaat zoeken.
[1638.32 --> 1640.68]  Hij heeft die code op je scherm voorbij zien komen.
[1641.20 --> 1642.16]  En dan kun je dus dingen vragen.
[1642.32 --> 1642.98]  Als help mij herinneren.
[1643.28 --> 1643.90]  Onthoud dit.
[1644.00 --> 1644.78]  En help mij herinneren.
[1644.84 --> 1646.22]  Als ik weer bij mijn deur ben.
[1647.04 --> 1648.52]  En omdat hij dus toegang heeft.
[1648.56 --> 1649.32]  Tot die camera constateert.
[1649.96 --> 1650.66]  Wat een deur is.
[1650.72 --> 1651.60]  Kan hij dat dan zeggen.
[1652.12 --> 1652.56]  Ja ik zit nu.
[1652.64 --> 1653.56]  Nu je dit allemaal vertelt.
[1653.68 --> 1654.22]  Zit ik te denken.
[1655.22 --> 1656.54]  Kan een ander bedrijf.
[1656.78 --> 1657.72]  Dan Google dit.
[1658.34 --> 1658.50]  Ja.
[1658.76 --> 1659.24]  Goeie vraag.
[1659.24 --> 1659.42]  Ik bedoel.
[1659.56 --> 1659.78]  Ik denk.
[1659.94 --> 1661.58]  OpenAI kan een end komen.
[1662.02 --> 1662.72]  Maar die hebben niet.
[1663.24 --> 1663.52]  Google Maps.
[1663.64 --> 1664.38]  De bustijden.
[1664.52 --> 1665.18]  En al die dingen.
[1665.94 --> 1666.74]  En ja.
[1666.74 --> 1667.62]  Dit is waarschijnlijk.
[1668.28 --> 1668.94]  Ik zit nu te denken.
[1669.10 --> 1669.36]  Want wij hebben.
[1669.40 --> 1670.10]  OpenAI heeft ook geen.
[1670.22 --> 1672.06]  Geen mobiel operating systeem.
[1672.16 --> 1673.28]  Waarbij ze op dat niveau.
[1673.74 --> 1675.12]  Het systeem kunnen gebruiken.
[1675.28 --> 1676.94]  Dus ik denk dat het nu een combinatie is.
[1677.04 --> 1677.26]  Van.
[1677.56 --> 1678.96]  Je moet een operating system hebben.
[1679.12 --> 1679.38]  In ieder geval.
[1679.42 --> 1680.22]  Dat hebben wij tot nu toe.
[1680.26 --> 1681.20]  Een beetje geconcludeerd.
[1681.28 --> 1681.46]  Van ja.
[1681.50 --> 1682.48]  Als je niet op die laag zit.
[1682.56 --> 1683.84]  Kan je het nagenoeg vergeten.
[1683.88 --> 1684.94]  Want je wordt gewoon nagebouwd.
[1684.94 --> 1685.58]  En geïntegreerd.
[1685.66 --> 1686.56]  Op de plek waar het toe doet.
[1687.04 --> 1687.48]  Toe doet.
[1687.52 --> 1688.30]  Door de andere partijen.
[1688.30 --> 1690.24]  Maar nu blijkt het natuurlijk ook.
[1690.34 --> 1692.74]  Dat het hebben van een goede gestandardiseerde dataset.
[1692.94 --> 1693.94]  Met realtime data.
[1694.08 --> 1694.52]  Heel vaak.
[1694.70 --> 1696.10]  En achterliggende data.
[1696.28 --> 1696.66]  Dat is ook het.
[1697.58 --> 1698.46]  Van project Astra.
[1698.58 --> 1698.88]  Is zo leuk.
[1698.94 --> 1700.10]  Want Astra is al iets ouder.
[1700.18 --> 1701.80]  Maar nu wordt het wat breder uitgerold.
[1701.80 --> 1703.28]  Dus dat je met je camera rondkijkt.
[1703.38 --> 1703.74]  Die al die.
[1704.04 --> 1704.48]  En die zegt.
[1704.66 --> 1704.86]  Oei.
[1704.98 --> 1706.66]  Volgens mij ben je nu op Kings Cross Station.
[1706.78 --> 1707.12]  In London.
[1707.38 --> 1708.04]  En dan is het.
[1708.36 --> 1708.48]  Ja.
[1708.52 --> 1709.58]  Ze hebben natuurlijk Street View.
[1710.02 --> 1710.20]  Maar.
[1710.72 --> 1712.00]  Heeft OpenAI Street View?
[1712.44 --> 1712.80]  Nee.
[1713.04 --> 1714.02]  Dus in dat opzicht.
[1714.40 --> 1716.56]  Als je gaat kijken naar alle potentiële datasets.
[1716.66 --> 1717.96]  Die Google kan openen.
[1718.06 --> 1719.90]  Die ze door de jaren heen al gekoppeld hadden.
[1719.96 --> 1720.68]  Van Google.com.
[1721.64 --> 1724.70]  Ze zitten op best wel een goede positie nu.
[1724.88 --> 1726.18]  Dus dat is een videootje van een gast.
[1726.28 --> 1728.76]  Want dit is dan je cameraatje omhoog gehouden.
[1728.82 --> 1729.74]  Wat natuurlijk heel awkward is.
[1729.74 --> 1730.92]  Want je ziet de hele tijd mensen lopen.
[1730.92 --> 1732.50]  Die dan met hun camera rondlopen.
[1732.62 --> 1734.12]  Alsof het een soort van Japanse toeristen zijn.
[1734.84 --> 1735.74]  Maar op een gegeven moment.
[1735.84 --> 1737.08]  Op de helft van die video.
[1737.90 --> 1738.86]  Laat ze dan ook zien.
[1739.02 --> 1739.18]  Hier.
[1739.30 --> 1740.18]  Dat is dan met je camera.
[1740.36 --> 1741.60]  Dit kan iedereen doen met zijn telefoon.
[1741.70 --> 1742.62]  Als dit straks uitkomt.
[1742.76 --> 1743.02]  Maar.
[1743.86 --> 1745.50]  Prototypen hebben we ook in die bril.
[1745.78 --> 1748.20]  Dus dan hebben ze zo'n meta Ray-Ban Glass achtige bril.
[1748.94 --> 1750.06]  Waar dat zelfde in gebeurt.
[1750.12 --> 1751.18]  Dan zie je dus een dude fietsen.
[1751.26 --> 1752.16]  Die die bril op heeft.
[1752.24 --> 1753.26]  Die kijkt dan naar een park.
[1753.58 --> 1755.52]  Naast de weg waar hij op dat moment fietst.
[1755.88 --> 1756.10]  En die zegt.
[1756.16 --> 1757.22]  Mag ik fietsen in dit park?
[1757.22 --> 1758.16]  En dan zegt dat ding.
[1758.56 --> 1760.26]  O dat is park bla bla bla.
[1760.92 --> 1762.24]  In Londen.
[1762.42 --> 1763.32]  Daar mag je niet fietsen.
[1763.40 --> 1765.96]  Maar het uiterste puntje van dit park.
[1766.06 --> 1767.16]  Waar je ook bij in de buurt bent.
[1767.24 --> 1768.06]  Als je daar binnen rijdt.
[1768.10 --> 1769.52]  Daar kun je wel heel erg leuk fietsen.
[1769.82 --> 1770.64]  Dan zegt hij vervolgens.
[1770.80 --> 1771.12]  Oké.
[1771.14 --> 1772.10]  Nou ik ga hierheen.
[1772.50 --> 1773.80]  Is er een supermarkt onderweg.
[1773.90 --> 1774.22]  Dan zegt hij.
[1774.26 --> 1774.38]  Ja.
[1774.52 --> 1775.60]  Er is een supermarkt op je route.
[1775.82 --> 1777.00]  Die zit op deze straat.
[1777.02 --> 1778.56]  En op deze straat zit er een supermarkt.
[1778.68 --> 1779.84]  Terwijl die aan het fietsen is.
[1780.46 --> 1782.60]  Dat is dus het combineren van die verschillende bronnen.
[1782.64 --> 1783.38]  Wat Google kan.
[1783.90 --> 1784.26]  Wat ook.
[1784.26 --> 1786.72]  Ik weet niet hoe zij dit gaan repliceren.
[1786.72 --> 1787.44]  Ook dit hele.
[1787.66 --> 1789.24]  Google kan gewoon zo'n stapje maken.
[1789.38 --> 1789.48]  Zo'n zo'n.
[1790.92 --> 1791.70]  Zo'n soort van.
[1791.80 --> 1792.08]  Oké.
[1792.14 --> 1793.84]  Dan neem je dan ook maar gewoon eventjes aan.
[1794.06 --> 1795.88]  Als er zal wel een of andere bril komen.
[1796.56 --> 1798.12]  Die Google gaat uitbrengen.
[1798.58 --> 1799.86]  Want ze laten ook nog zien met.
[1800.88 --> 1802.44]  Zo'n visuele pop-up.
[1802.56 --> 1802.86]  Die in beeld.
[1802.94 --> 1803.78]  Dus niet alleen maar stem.
[1803.90 --> 1805.42]  Maar hij krijgt ook soort van tekstballonnetjes.
[1805.50 --> 1807.00]  In zijn vizier te zien met antwoorden.
[1807.94 --> 1808.04]  Ja.
[1808.50 --> 1810.00]  Ik denk dat op zich wel interessant hoor.
[1810.04 --> 1811.50]  Want die computer use van Antropic.
[1811.64 --> 1812.78]  Dat ze je computer gaan gebruiken.
[1812.86 --> 1813.84]  Wat Gemini nu ook kan.
[1814.92 --> 1817.70]  Daarin gaat Antropic dan Google gebruiken.
[1817.84 --> 1818.46]  Op jouw computer.
[1819.20 --> 1820.62]  Dus die dame die dit videotje doet.
[1820.62 --> 1821.30]  Die vraagt dan van.
[1821.34 --> 1823.72]  Ik ben op zoek naar voor mij een leuke plek ergens.
[1823.86 --> 1825.00]  En dan gaat hij naar Google.com.
[1825.08 --> 1826.26]  En dan die leuke plek opzoeken.
[1826.76 --> 1829.88]  Waarbij Antropic eigenlijk ook al meteen de handdoek in de ring gooit.
[1829.98 --> 1830.22]  En zegt.
[1830.92 --> 1832.40]  Antropic gaat nooit een search engine bouwen.
[1832.50 --> 1833.64]  Dus we gebruiken gewoon Google.
[1834.04 --> 1835.04]  En misschien ook wel zegt.
[1835.48 --> 1836.18]  Het is niet erg.
[1836.60 --> 1838.46]  Dat wij voor deze taken Google gebruiken.
[1838.66 --> 1839.04]  Maar ja goed.
[1839.40 --> 1839.60]  Google.
[1839.76 --> 1841.52]  De lijntjes zijn een stuk korter bij Google.
[1841.72 --> 1843.44]  Wat betreft integratie potentieel.
[1843.70 --> 1844.66]  Nou je hebt het er al over.
[1844.78 --> 1847.00]  Dit is inderdaad wat zij noemen Project Mariner.
[1847.00 --> 1849.88]  Een Chrome extensie die je browser kan besturen.
[1850.00 --> 1851.74]  Het is een klein knopje bovenin Chrome.
[1851.88 --> 1853.32]  Die een soort zijbalk opent.
[1854.00 --> 1857.84]  En waar inderdaad Antropic experimenteert met computer use.
[1858.00 --> 1859.76]  En waar open hij in met operator.
[1860.10 --> 1862.48]  Dus systemen die je scherm zien.
[1862.62 --> 1864.50]  En dan ook je muis overnemen.
[1865.04 --> 1868.80]  Heeft Google dit nu voor het eerst gedemonstreerd met Project Mariner.
[1868.80 --> 1872.56]  En ze lieten allerlei live demonstraties zien.
[1872.66 --> 1875.66]  Dit is niet beschikbaar voor breder publiek.
[1876.20 --> 1880.92]  Maar ze lieten in demonstraties zien hoe een AI agent zelfstandig door een webshop gaat.
[1881.06 --> 1882.12]  Inlogt op een gebruikersaccount.
[1882.20 --> 1883.20]  Winkelwagentje vult.
[1884.00 --> 1889.22]  En zelfs vervangende producten koos toen een bepaald item niet op voorraad was.
[1889.90 --> 1893.22]  En die dit gewoon inderdaad aan het doen is in Chrome.
[1893.40 --> 1897.72]  Dus dan heb je heel veel niveaus in die hele stack hebben we nu gehad.
[1897.72 --> 1900.36]  Op hardware niveau hebben we het gehad.
[1900.44 --> 1901.26]  Over Android.
[1901.86 --> 1903.20]  Over brillen.
[1904.12 --> 1906.88]  En gewoon op je gewone computer.
[1908.28 --> 1909.62]  Want dat heeft Google natuurlijk ook.
[1909.82 --> 1910.80]  Ik moet niet vergeten.
[1910.90 --> 1913.28]  Chromebooks zijn ook een onwijs grote categorie.
[1913.30 --> 1913.82]  Zeker weten.
[1914.16 --> 1916.84]  Dan heb je het niveau van het operating systeem.
[1916.90 --> 1918.72]  Wat ze dan op mobiel wel...
[1919.24 --> 1919.58]  Ownen.
[1919.70 --> 1920.50]  Ja, wel ownen.
[1921.20 --> 1923.18]  En dan heb je het browser niveau.
[1923.76 --> 1926.58]  Met Chrome ook de grootste browser.
[1926.58 --> 1928.30]  En dan...
[1928.30 --> 1931.42]  Ja, lange tijd liep dat gewoon de hele tijd achter qua model.
[1931.90 --> 1933.58]  Dan was het een soort van...
[1934.40 --> 1937.62]  Een soort van Albert Heijn huismerkachtig ding.
[1937.72 --> 1939.42]  Het hobbelt achter de aanmerken aan.
[1939.82 --> 1942.00]  Het kan hetzelfde voor iets goedkoper.
[1942.10 --> 1943.78]  Maar er is weinig om enthousiast over te worden.
[1944.32 --> 1945.42]  En wat zij nu lanceren.
[1945.46 --> 1949.52]  Want we hebben nu nog steeds maar een heel klein deel besproken van wat er allemaal uitkomt.
[1949.52 --> 1951.94]  We hebben vijf afleveringen nodig van deze podcast hiervoor.
[1951.94 --> 1954.78]  En zelfs in dat model is het nu...
[1954.78 --> 1957.36]  Want wat kunnen ze nog meer behalve stemmen genereren?
[1957.58 --> 1959.02]  Hij kan ook plaatjes genereren.
[1959.20 --> 1961.32]  Je kan vragen stellen om plaatjes te bewerken.
[1962.06 --> 1962.94]  Hij kan...
[1963.54 --> 1964.94]  Wat mis ik nou nog allemaal?
[1965.74 --> 1966.66]  In die...
[1966.66 --> 1970.26]  Ze hebben een soort van prompt gallery gemaakt met allemaal dingen die je ermee kan doen.
[1970.26 --> 1973.70]  Hij kan op Google Maps dingen plotten.
[1974.16 --> 1975.10]  Je kan...
[1975.10 --> 1977.10]  Het is echt ongelooflijk hoeveel...
[1977.10 --> 1979.42]  Je kan plaatjes herkennen.
[1979.52 --> 1980.50]  Dat vond ik ook nog best wel grappig.
[1980.58 --> 1985.02]  Dus de basis die je nodig heeft om die bril te kunnen dragen.
[1985.10 --> 1985.82]  En dan te herkennen.
[1986.00 --> 1988.86]  Oké, ik zie nu een verkeersbord en dit staat erop.
[1989.48 --> 1991.10]  Kun je dus ook...
[1992.56 --> 1997.30]  Je kunt die videoanalyse en die plaatjesanalyse...
[1997.30 --> 1998.28]  Kun je dus ook...
[1998.28 --> 1999.16]  Dat je bijvoorbeeld...
[1999.16 --> 2001.04]  Als programmeur is dat handig.
[2001.14 --> 2002.78]  Dat je dingen kan labelen.
[2002.96 --> 2004.04]  Dus dat je een plaatje erin kunt.
[2004.10 --> 2004.90]  En dat die dan zegt...
[2004.90 --> 2007.46]  Waar op de foto staat...
[2007.46 --> 2009.16]  Weet ik veel...
[2009.16 --> 2009.86]  Een planten...
[2009.86 --> 2010.68]  Of een bloemenpot.
[2011.34 --> 2013.56]  En dan kan hij dus zo'n hok door hem heen tekenen.
[2013.70 --> 2015.44]  En dat er dan bloempot boven komt te staan.
[2015.56 --> 2017.58]  En dan ook daarachter schaduw van de bloempot.
[2017.94 --> 2019.22]  En dat is natuurlijk weer nodig.
[2019.22 --> 2022.02]  Om dit als API in je eigen apps te kunnen gebruiken.
[2022.14 --> 2023.22]  Waardoor je dingen kan bouwen als...
[2023.90 --> 2025.32]  Waar heb ik mijn telefoon gelaten?
[2025.32 --> 2028.54]  En dat je dan telefoon kan zien in een foto.
[2028.62 --> 2030.38]  En dat je dat als developer ook kan gebruiken.
[2030.48 --> 2032.24]  Om apps te maken waarmee je...
[2032.24 --> 2033.96]  Bewust bent van je omgeving.
[2034.18 --> 2035.58]  Ja en ik denk dat er...
[2035.58 --> 2036.60]  Veel van deze dingen...
[2036.60 --> 2038.32]  Want ik hoor nu mensen bijna roepen...
[2038.32 --> 2040.04]  Ja maar het komt toch al met Google Lens.
[2040.42 --> 2042.24]  Kijk het punt is...
[2042.24 --> 2043.92]  Al dat waren allemaal losse modellen.
[2044.44 --> 2045.74]  Losse teams binnen Google.
[2046.18 --> 2048.36]  En met Google Lens kon je al wijzen naar spijkerbroeken.
[2048.36 --> 2049.78]  En dan zei hij dat is die en die Levi's.
[2049.84 --> 2050.52]  En dan kon je hem bestellen.
[2050.62 --> 2051.66]  Dat kan al een aantal jaar.
[2051.88 --> 2052.16]  Cool.
[2052.64 --> 2055.08]  En vakjes tekenen op dingen kon ook al een aantal jaar.
[2055.32 --> 2056.16]  Losse teams.
[2056.50 --> 2057.14]  Losse modellen.
[2057.54 --> 2059.24]  En nu zit overal Gemini achter.
[2059.76 --> 2060.96]  En dat is ontzettend krachtig.
[2061.02 --> 2064.68]  Omdat dat model dan ook ineens allerlei bijcapaciteiten krijgt.
[2064.74 --> 2065.86]  Die is soort van gratis.
[2065.94 --> 2066.60]  Tussen air quotes.
[2066.76 --> 2067.92]  Want er zit energieprobleem achter.
[2068.08 --> 2068.32]  Prima.
[2068.76 --> 2070.08]  Maar die zitten er ook in.
[2070.56 --> 2071.38]  En dat is ook...
[2071.38 --> 2073.18]  Ik maak dit punt ook vaak naar mensen.
[2073.26 --> 2073.62]  Dat ik zeg...
[2073.62 --> 2076.58]  Als je straks synthetische collega's in jouw teams calls hebt zitten.
[2077.08 --> 2078.28]  Die en een gezicht hebben.
[2078.34 --> 2079.40]  Want hij kan gezichten maken.
[2079.82 --> 2080.58]  En praten.
[2080.64 --> 2081.46]  Want hij kan ook audio.
[2082.04 --> 2083.38]  En naar je luisteren.
[2083.42 --> 2084.34]  Want hij kan ook luisteren.
[2084.68 --> 2086.22]  En dat je ook even zegt...
[2086.22 --> 2088.30]  Beste notulist die eigenlijk draait op Gemini.
[2089.10 --> 2092.80]  Die ene theorie over hoe je management eigenlijk het best kan toepassen uit de jaren negentig.
[2092.88 --> 2093.98]  Dat weet dat ding ook.
[2094.22 --> 2095.72]  Omdat dat er ook allemaal achter zit.
[2095.72 --> 2102.60]  En ik denk dat we eigenlijk nog nooit echt oog in oog hebben gestaan met zo'n soort manesje van alle super Wikipedia intelligentie.
[2102.66 --> 2104.36]  Die trouwens ook nog liedjes kan zingen.
[2104.92 --> 2106.02]  Het is heel wauws.
[2106.22 --> 2108.04]  En nu komen heel veel lijntjes.
[2108.14 --> 2109.96]  Ik denk dat wij daarom allebei...
[2109.96 --> 2113.14]  Want ik ben eigenlijk wel heel blij dat het jou nog lukt om hierover te praten.
[2113.24 --> 2115.08]  Want ik loop een beetje vast merk ik ook.
[2115.12 --> 2116.60]  Omdat het zo allesomvattend is.
[2116.74 --> 2119.08]  Ja en ik had echt weer...
[2119.08 --> 2121.08]  Ik zat gisteravond allemaal een beetje door te nemen.
[2121.18 --> 2122.04]  En YouTube video's te kijken.
[2122.16 --> 2123.44]  En vanochtend weer te lezen en te doen.
[2123.44 --> 2125.16]  En ik merkte gewoon van...
[2125.16 --> 2128.34]  Ik ben daar weer een soort essentieel overweldigd.
[2128.44 --> 2130.44]  Wat veel mensen voelen nadat ik met ze praat.
[2131.06 --> 2132.40]  Dat ik het nu zelf weer heb.
[2132.48 --> 2134.44]  Dat ik denk...
[2134.44 --> 2137.44]  Ik probeer ook mezelf weer even uit te dagen van...
[2138.48 --> 2141.38]  Ja we hebben het in stukjes allemaal wel gezien door de jaren heen.
[2141.72 --> 2143.90]  We hebben het in stukjes gezien bij concurrenten.
[2144.34 --> 2150.58]  Maar we hebben het nog niet allemaal in één groot super ding gezien vanuit de grote Google.
[2150.58 --> 2153.58]  En ik denk dat in dat opzicht...
[2153.58 --> 2155.92]  In de inhoudrace lopen ze nu on par.
[2156.04 --> 2158.36]  Met een paar plekken waarop ze zelfs voorbij zijn gegaan.
[2158.46 --> 2160.58]  Met een vrij klein snel betaalbaar.
[2161.18 --> 2162.58]  In ieder geval qua computerkracht model.
[2164.00 --> 2168.20]  En daarachter ook nog eens een potentiële bestaande markt hebben.
[2168.58 --> 2169.08]  En ja...
[2169.08 --> 2170.30]  Lock in in de negatieve zin.
[2170.42 --> 2172.84]  Of enthousiast gebruik van gebruikers in de positieve zin.
[2172.84 --> 2175.14]  Waardoor ze ook dit kunnen gaan uitrollen.
[2175.82 --> 2176.84]  En ja...
[2176.84 --> 2178.18]  Ik denk daarin...
[2178.18 --> 2180.10]  Ik ga ervan uit...
[2180.10 --> 2183.18]  Dat er toch wel wat zenuwen zijn nu.
[2183.40 --> 2186.72]  Dat er een andere sfeer hangt bij Entropic en bij OpenAI.
[2187.60 --> 2189.46]  Ik bedoel die kijken er natuurlijk ook wel vooruit.
[2189.56 --> 2192.38]  Die hebben ook hun contacten in de industrie om te zien waar het naartoe gaat.
[2192.82 --> 2194.84]  Maar ik zou echt...
[2194.84 --> 2198.60]  Een all ends on super meeting doen nu.
[2198.60 --> 2202.92]  Van hoe gaan wij hier in ons nu goed bedrijven tot een half jaar geleden.
[2203.02 --> 2206.84]  Maar zo voel ik dat dan nu als de persoon die niet in die kamer zit.
[2207.08 --> 2207.44]  Maar toch.
[2207.58 --> 2211.06]  Dit is denk ik vergelijkbaar met ChatGPT.
[2211.58 --> 2212.54]  Voordat ChatGPT...
[2212.54 --> 2214.38]  Of met OpenAI voordat ChatGPT uitkwam.
[2214.50 --> 2217.68]  In de zin dat de manier waarop je nu bij al deze tooling kan komen.
[2217.84 --> 2219.82]  Is best wel voor developers.
[2220.38 --> 2223.28]  Dus die manier waarop die AI studio bijvoorbeeld werkt.
[2223.48 --> 2226.16]  Is dit gaat mijn moeder niet doen.
[2226.16 --> 2229.56]  Want daarvoor is dit allemaal niet intuïtief genoeg.
[2229.70 --> 2233.14]  En zit het niet geïntegreerd in de tools die de meeste mensen iedere dag gebruiken.
[2233.74 --> 2237.34]  En het zijn allerlei hintjes naar hoe het gaat zijn.
[2237.46 --> 2240.06]  Er zijn video's waarbij bijvoorbeeld Excel.
[2240.54 --> 2242.14]  Of de Google Sheets versie bedoel ik.
[2242.50 --> 2243.58]  Die Google Drive versie.
[2243.66 --> 2244.50]  Google Sheets heet dat.
[2244.70 --> 2245.36]  De Excel van Google.
[2245.50 --> 2246.04]  Volgens mij wel ja.
[2246.18 --> 2247.90]  Waarbij ze een tabel maken.
[2248.08 --> 2248.80]  Waarbij die...
[2248.80 --> 2249.68]  Hoe noemen ze het?
[2249.76 --> 2250.12]  Mariner.
[2250.36 --> 2252.82]  Die agentic AI.
[2252.82 --> 2255.28]  Die dus je computer voor je bedient.
[2255.28 --> 2257.00]  Die in feite die...
[2257.00 --> 2262.14]  Die gebruiker stelt een aantal vragen over hoe die spreadsheet gemaakt moet worden.
[2262.26 --> 2263.16]  En die computer doet dat.
[2263.44 --> 2265.24]  Wat mensen hoopten dat ProPilot kon.
[2265.60 --> 2266.20]  Kan dit nu.
[2266.28 --> 2266.52]  Precies.
[2267.22 --> 2270.22]  Maar het zit nog niet nu geïntegreerd in.
[2270.38 --> 2270.56]  Nee.
[2270.56 --> 2274.40]  Al die Google soort van endpoints.
[2274.60 --> 2276.42]  De punten waar de gebruiker...
[2276.42 --> 2278.28]  De apps die Google gebruikt.
[2278.28 --> 2278.98]  Ja, maar ik denk ook...
[2278.98 --> 2280.64]  Daar zit dit allemaal nog niet in.
[2280.72 --> 2282.90]  En het is voor ons makkelijk om te zien...
[2282.90 --> 2284.20]  Hoe gaat dit eruit zien.
[2284.30 --> 2287.36]  Dat je op Android de assistent kan gebruiken.
[2287.50 --> 2288.08]  En die scherm...
[2288.08 --> 2288.92]  Dat dat ding weet.
[2288.96 --> 2289.52]  Dat die scherm kan zien.
[2289.58 --> 2290.50]  Dat die gaat zeggen tegen...
[2290.50 --> 2291.36]  Hou even je camera omhoog.
[2291.44 --> 2292.74]  Dan kan ik zien wat jij ook ziet.
[2292.84 --> 2295.62]  Op het moment dat je iets wil weten over je omgeving.
[2295.84 --> 2297.70]  Of wij kunnen ons helemaal nu...
[2297.96 --> 2300.62]  Qua fantasie kunnen wij ons voorstellen...
[2300.62 --> 2302.48]  Hoe dit in software geïntegreerd gaat worden.
[2302.58 --> 2304.26]  Maar daar zijn we nog niet.
[2304.36 --> 2306.70]  Hoe lang denk je dat dat gaat duren bij Google?
[2306.96 --> 2309.58]  Nou, ik neem vaak het voorbeeld...
[2309.58 --> 2310.88]  Als ik een lezing geef...
[2310.88 --> 2311.98]  Laat ik vaak video's zien.
[2312.34 --> 2314.84]  En in die video's heb ik vaak de subtitles aanstaan.
[2315.22 --> 2316.98]  Die subtitles die kloppen heel vaak niet.
[2317.24 --> 2319.44]  Dan krijg ik daar natuurlijk meteen commentaar op.
[2319.70 --> 2321.22]  Van je staat hier een verhaal te vertellen...
[2321.22 --> 2322.20]  Over alles wordt anders.
[2322.44 --> 2323.56]  Maar die is zeker een nieuw ding.
[2323.96 --> 2326.18]  En die Engelse ondertiteling staan allemaal verkeerde woorden.
[2326.70 --> 2327.86]  Dus ik benoem dat natuurlijk.
[2328.02 --> 2328.66]  Dat ik zeg...
[2328.66 --> 2329.82]  Nou, hebben jullie net die video gezien.
[2329.88 --> 2331.00]  Die was heel erg indrukwekkend.
[2331.10 --> 2332.68]  Maar jullie hebben natuurlijk ook mee zitten lezen.
[2333.16 --> 2333.98]  Dat ging gewoon nog mis.
[2333.98 --> 2335.02]  Zelfs in het Engels.
[2335.50 --> 2336.86]  Dat komt omdat er op YouTube...
[2336.86 --> 2337.86]  Het zal zijn...
[2337.86 --> 2340.02]  100 uur video per seconde geüpload wordt.
[2340.46 --> 2341.86]  Daar draait een taalmodelletje achter.
[2341.96 --> 2344.04]  Dat is helemaal nog niet zo'n ding als wat in Gemini...
[2344.04 --> 2344.96]  Of een transformermodel.
[2345.36 --> 2346.54]  Want die moet...
[2346.54 --> 2348.00]  Dat is waarschijnlijk zelfs een chip geworden...
[2348.00 --> 2349.38]  Die ze inmiddels tot chip gebakken hebben.
[2349.44 --> 2350.56]  Want ze konden het niet bijhouden.
[2351.06 --> 2353.46]  Dat duurt wel even voordat jij je infrastructuur...
[2353.46 --> 2355.22]  Ten eerste voordat je het vervangt.
[2355.26 --> 2356.18]  Want je hebt nog iets draaien.
[2356.24 --> 2357.78]  Dan moet je ook nog economisch afschrijven.
[2358.70 --> 2359.66]  En ten tweede...
[2359.66 --> 2361.72]  Dat je dit kunt toepassen in de breedte.
[2361.72 --> 2362.00]  Ja.
[2362.18 --> 2363.92]  Want we zitten nu weer in de laatste week...
[2363.92 --> 2365.10]  Met miljarden gebruikers bedoel je.
[2365.16 --> 2365.42]  Exact.
[2365.54 --> 2366.74]  Want de laatste weken is...
[2366.74 --> 2369.44]  En Tropic website klapte de hele tijd uit.
[2369.68 --> 2369.94]  Zeg maar.
[2370.02 --> 2371.66]  En dat zijn bedrijven die hebben diepe zakken.
[2371.82 --> 2372.56]  Emmeron zit erin.
[2372.56 --> 2374.24]  Zora ging aan en moest gelijk weer uitgezet worden.
[2374.32 --> 2375.18]  Gaan ze straks over hebben.
[2375.30 --> 2375.44]  Ja.
[2375.54 --> 2376.34]  Die wisten dat toch.
[2376.40 --> 2376.88]  Weet je al goed.
[2377.00 --> 2380.34]  Aan alle kanten piept en kraakt het bij al die AI platforms.
[2380.56 --> 2383.28]  Dat zegt ook iets over trouwens hoe erg de adoptie is.
[2383.40 --> 2383.72]  Namelijk gigantisch.
[2384.34 --> 2386.32]  Want ik geloof niet dat er hele slechte datacenters achter zitten.
[2386.32 --> 2391.18]  Ik geloof dat zelfs in hun meest optimistische scenario's niet verwachten dat het eruit komt.
[2391.66 --> 2393.10]  Of dat het zo uitkomt.
[2393.70 --> 2395.02]  Maar dat laat wel wat zien.
[2396.08 --> 2398.18]  Nou, nog leuker, concreter voorbeeld misschien.
[2398.56 --> 2399.62]  Ik had het gisteren met iemand over.
[2399.74 --> 2403.38]  En die zei, waarom moet ik trouwens als ik die modellen kies steeds voor België of Zweden kiezen?
[2403.96 --> 2405.92]  Ja, alles is op.
[2406.92 --> 2407.28]  Zeg maar.
[2407.46 --> 2410.56]  Als je in Europa een taalmodel wil draaien bij Microsoft of bij Google.
[2410.70 --> 2413.48]  Dan heb je in de drop-down allemaal uitgegrijsde landen staan.
[2413.48 --> 2416.28]  En Zweden één en België.
[2416.64 --> 2417.24]  En dat komt gewoon...
[2417.24 --> 2418.20]  Die zijn nog over, bedoel je?
[2418.30 --> 2426.02]  Ja, en de mist natuurlijk, dat begrijp ik bij heel veel mensen, het besef dat er wel ergens een datacenter moet zijn met die Nvidia kaarten.
[2426.10 --> 2427.68]  Want over het algemeen zijn dat het nog steeds.
[2428.26 --> 2429.88]  En als die op zijn, dan...
[2429.88 --> 2430.70]  En het is op.
[2430.84 --> 2431.52]  De pizza is op.
[2431.82 --> 2432.82]  Het houdt hier gewoon op.
[2432.82 --> 2435.22]  Er zit een hele fysieke realiteit aan de cloud, zeg maar.
[2435.46 --> 2438.78]  Dus jouw vraag, hoe zit het met uitrollen?
[2439.10 --> 2446.06]  Kijk, ik voel ook wel een beetje aankomen, want die computer use, dus de agentic AI waarin een agent jouw computer overneemt.
[2446.44 --> 2453.66]  En dan is daarbij het idee denk ik ook dat Google gaat zeggen, joh, je kan een duplicaat van jouw Chromebook draaien in de cloud, zodat die ook s'nachts doorgaan terwijl je laptop dicht is.
[2454.30 --> 2456.22]  Ook daar zijn ze weer uniek geëquipeerd.
[2456.32 --> 2457.32]  Man, man, man, man, man.
[2457.38 --> 2457.82]  Niet normaal.
[2457.94 --> 2458.80]  Aan de Google-kopen.
[2459.14 --> 2459.80]  Ja, nou ja.
[2460.20 --> 2462.46]  Dit is geen advies, maar het gaat goed met Google.
[2462.46 --> 2467.46]  Dat ik me ook kan voorstellen dat er best wel wat...
[2468.12 --> 2474.46]  Kijk, de media, zeg maar gewoon, of mensen die het leuk vinden als artikelen gelezen worden, het...
[2475.50 --> 2481.02]  Gemini bestelt cruise van 3000 euro voor vrouwen die niet eens weten dat ze Gemini geïnstalleerd had.
[2481.12 --> 2482.56]  Ja, dit gaat allemaal komen.
[2482.72 --> 2485.18]  Dus agents die heel veel geld gaan uitgeven.
[2485.32 --> 2486.74]  Agents die dingen gaan posten namens mensen.
[2486.74 --> 2489.68]  Ja, ik bedoel te zeggen, dit gaat heel vaak mis, deze dingen.
[2489.76 --> 2492.70]  En er gaan allerlei sexy, juicy verhalen uitkomen.
[2492.80 --> 2498.16]  Luister, toen ze geprobeerden Gemini in Google te doen, was binnen twaalf uur pizza met benzine erop.
[2498.40 --> 2501.02]  Iedereen ging los, want AI is dom en hallucineerd.
[2501.16 --> 2503.04]  En Google, oeps, oeps, oeps, sorry, sorry, sorry, sorry.
[2503.12 --> 2504.68]  Nu rollen ze gewoon nog verder, maar goed.
[2506.28 --> 2510.02]  Er zitten een aantal vertragende factoren op de uitrol van deze technologie.
[2510.52 --> 2512.08]  Het is nog best wel alpha, beta.
[2512.08 --> 2514.78]  Het woord experimental staat twintig keer op de websites van Gemini.
[2514.78 --> 2517.48]  Alleen kleine groepjes mogen erbij, et cetera, et cetera, et cetera.
[2518.04 --> 2519.34]  Maar dit laat wel zien.
[2519.82 --> 2523.60]  En ik moet zeggen, ik heb ook een beetje het idee gekregen bij Google inmiddels.
[2523.96 --> 2528.06]  Dat ze van een achterstand, waarin ze simpelweg een beetje de boot misten.
[2528.34 --> 2530.20]  Omdat openen jij er met hun research vandoor ging.
[2530.34 --> 2532.24]  Net als met Xerox en Apple is tijdens.
[2532.52 --> 2534.40]  Dat Google inmiddels weer bij is.
[2534.92 --> 2538.50]  Maar ook, dit is een aanname van mij, zoiets heeft van.
[2539.36 --> 2542.50]  Laat eerst die andere partij het maar een beetje proberen.
[2542.50 --> 2545.00]  Met computer use en zo.
[2545.08 --> 2546.96]  En als we voelen dat de markt dat wel ziet zitten.
[2547.46 --> 2549.02]  En dat zijn niet hele grote controversies.
[2549.14 --> 2551.42]  Dan komen wij daar wel als derden een beetje achteraan.
[2551.52 --> 2555.02]  Alsof ze een soort van een andere cabaretier hele grove grappen laten testen op het podium.
[2555.50 --> 2558.56]  En als het publiek die grappen wel kan hebben, gaan ze ze ook opnemen in hun line-up.
[2559.00 --> 2561.70]  Want wat we tot nu toe allemaal geïntroduceerd hebben gekregen.
[2561.96 --> 2565.44]  Op die coole audio feature na met die kuchjes en die lachjes en die emotie erin.
[2565.74 --> 2567.46]  Er is niets nieuws onder de zon.
[2568.00 --> 2568.96]  Maar het is wel Google.
[2568.96 --> 2572.44]  En Google doet mee en Google heeft al die connecties.
[2572.96 --> 2574.82]  En dat vind ik wel een groot ding.
[2574.90 --> 2578.58]  En ik denk dat wij allebei best wel goed aanvoelen nu.
[2578.72 --> 2582.00]  Van ja maar wacht even, als we die linkjes allemaal gaan leggen nu.
[2582.52 --> 2584.48]  Dan zitten ze best goed.
[2584.62 --> 2586.06]  Ja het moet nog wel even ingebouwd worden.
[2586.06 --> 2593.14]  Google is van een bedrijf wat ooit heel snel nieuwe features uitbracht.
[2593.22 --> 2595.60]  In Google Maps, in Google Foto's, in Gmail.
[2596.14 --> 2600.06]  Verwoorden tot een bijna Salesforce, Microsoft-esque bedrijf.
[2600.72 --> 2603.46]  Waarbij interfaces totaal clutterd zijn.
[2603.64 --> 2606.90]  En het heel lang duurt voordat nieuwe features uitgerold worden.
[2606.98 --> 2610.06]  In die apps die door honderden miljoenen mensen gebruikt worden.
[2610.06 --> 2617.26]  Ik moet nog maar even zien hoe dit in Android, in Gmail, in Google Drive allemaal geïntegreerd wordt.
[2617.50 --> 2622.12]  Het bedrijf heeft gewoon de afgelopen jaren niet laten zien dat ze echt kunnen executen daarop.
[2622.16 --> 2627.44]  Wat Microsoft op dit moment eerlijk gezegd sneller doet in Windows dan Google.
[2627.70 --> 2629.08]  Dat is mijn enige punt van zorg.
[2629.20 --> 2631.42]  Dat er dus een backend onder zit die fantastisch is.
[2631.60 --> 2635.36]  Maar om gewoon een softwareorganisatie te hebben die niks kan opleveren.
[2635.56 --> 2638.00]  Maar goed die backend is niet bedoeld voor Google developers alleen.
[2638.00 --> 2646.46]  Dus ik kan me voorstellen als jij nu, zullen er inmiddels in Nederland zijn, minimaal 10 bedrijven die synthetische podcast aanbieden als product.
[2647.04 --> 2650.08]  Als die nu naar hun pipeline gaan en dat dingetje veranderen in Gmail 2.
[2650.48 --> 2652.72]  Dan komen daar ineens veel betere podcasts uit.
[2652.74 --> 2654.66]  Ja, maar we hebben het hier nu de hele tijd over.
[2654.86 --> 2656.86]  Omdat Google dus een unieke speler is.
[2656.96 --> 2661.32]  Omdat zij zoveel verschillende elementen in één bedrijf hebben.
[2661.48 --> 2664.06]  Dus ook Google Maps en ook toegang tot de YouTube database.
[2664.18 --> 2667.10]  Dat hebben we nog niet eens over toegang tot het opverenigingssysteem van de gebruikers.
[2667.10 --> 2668.22]  Ze hebben zo'n potentie.
[2668.42 --> 2669.68]  Wanneer gaan ze oogsten bedoel jij?
[2669.84 --> 2671.62]  Ja, het is echt tering.
[2672.00 --> 2672.88]  Het duurt zo lang.
[2672.92 --> 2674.84]  Zonder dat ze niet oogsten op hun netwerk.
[2674.90 --> 2678.68]  Ja, dit is de soort van negatieve case voor het aandeel Google.
[2678.94 --> 2682.86]  Dat ze wel, dat ze dit, ze hebben nu enorm doorgeschakeld.
[2682.86 --> 2689.08]  Om die serieuze speler in AI te worden die ze al jaren willen zijn.
[2689.20 --> 2690.60]  Nog voordat JetTip die uitkwam.
[2691.46 --> 2693.16]  Maar ik heb gewoon nog geen bewijs.
[2693.30 --> 2696.22]  Hoe Gemini werkt op Android is zo kut.
[2696.60 --> 2701.66]  Zeg maar, het heeft meer dan een jaar geduurd voordat je een timer kon instellen via Gemini.
[2701.66 --> 2701.94]  Ja, zeker.
[2701.94 --> 2706.70]  Het is gewoon moeilijk om te begrijpen voor een eindgebruiker.
[2707.20 --> 2708.70]  Dat je zulke vette shit kan doen.
[2708.82 --> 2712.16]  Dat je je live video kan streamen in zo'n playground.
[2712.58 --> 2713.96]  Dat AI studio.
[2714.62 --> 2716.50]  Maar dat je niet eens een fucking timer kan instellen.
[2716.72 --> 2721.56]  Dat maakt voor mij dat bedrijf zo moeilijk om als consumentensoftware.
[2722.90 --> 2725.46]  Ik nam dat heel serieus lang geleden.
[2725.82 --> 2729.12]  En inmiddels denk ik gewoon, wat hebben ze de afgelopen jaren gedaan op dat gebied?
[2729.24 --> 2730.04]  Consumer facing.
[2730.04 --> 2731.60]  Nee, snap ik. Maar ik ben wel benieuwd.
[2731.72 --> 2734.48]  Ik bedoel, als we even teruggaan naar, ik noem het als Xerox Spark.
[2734.76 --> 2736.44]  Het research lab van Xerox.
[2736.54 --> 2740.18]  Waar zowel Steve Jobs als Bill Gates een demo hebben gekregen van.
[2740.34 --> 2741.94]  En de grafische gebruikersinterface.
[2742.32 --> 2743.16]  En de muis.
[2743.42 --> 2746.00]  Toen nog een heel revolutionair doosje met een paar knopjes erop.
[2746.58 --> 2749.54]  Ik denk dat er best wel wat jaren hebben gezeten tussen die dag daar.
[2749.54 --> 2751.18]  Waarin zij naar buiten liepen en beseften.
[2751.32 --> 2753.32]  Alles wordt anders en wij moeten hier iets mee.
[2753.70 --> 2759.06]  Tot de eerste muizen van Microsoft die bij een IBM PC zaten met Windows en een grafische interface.
[2759.06 --> 2760.86]  Nou ja, ik bedoel.
[2761.58 --> 2762.72]  Mijn vraag is eerder.
[2762.88 --> 2764.68]  Is dit zo uniek aan Google?
[2764.94 --> 2766.98]  Omdat je net Microsoft als voorbeeld noemt.
[2767.48 --> 2772.56]  Of is het gewoon op grote schaal uitrollen in zo'n grote superorganisatie toch wel pittig?
[2772.88 --> 2773.62]  Nou, dat was Google.
[2774.00 --> 2779.48]  Maar Google was niet het enige bedrijf wat deze week een soort van cadeautje aan het uitpakken is.
[2779.62 --> 2780.78]  OpenAI is de tweede.
[2780.78 --> 2786.00]  En ook daar is een onwaarschijnlijke bak aan nieuwe functionaliteit gelanceerd.
[2786.14 --> 2787.00]  Gaan we het straks over hebben.
[2787.08 --> 2788.46]  Maar eerst een boodschap van onze sponsor.
[2790.98 --> 2795.56]  Want met Squarespace kan je tegenwoordig namelijk AI inzetten om je website te bouwen.
[2795.70 --> 2797.36]  Design intelligence noemen ze het.
[2797.82 --> 2801.88]  En die AI gestuurde tool combineert twintig jaar design ervaring met de nieuwste technologie.
[2802.14 --> 2804.76]  Om jouw stijl naadloos te vertalen naar het web.
[2805.34 --> 2810.58]  Met de visuele ontwerptools in hun dashboard creëer je moeiteloos een professionele uitstraling die bij jouw merk past.
[2810.58 --> 2815.36]  Kies uit honderden moderne templates die je site laten opvallen, ongeacht je branche of je doelgroep.
[2815.88 --> 2819.66]  En daarnaast kun je nu ook conceptteksten genereren binnen Squarespace, ook weer met AI natuurlijk.
[2820.16 --> 2823.38]  Voor bijvoorbeeld SEO, om beter ontdekt te worden via zoekmachines.
[2823.62 --> 2827.64]  Of om goede overtuigende teksten te produceren voor een krachtige call to action.
[2828.38 --> 2831.18]  Of je nou een opkomend kunstenaar bent of gevestigde consultant.
[2831.66 --> 2836.14]  Squarespace geeft je de vrijheid om je online aanwezigheid vorm te geven, precies zoals jij dat wil.
[2836.60 --> 2837.74]  Zelf beginnen? Dat kan.
[2837.74 --> 2842.02]  Ga naar squarespace.com slash poky10 voor een gratis proefperiode van 14 dagen.
[2842.18 --> 2849.24]  En als je besluit de site te lanceren, gebruik dan de promocode poky10 voor 10% korting op je eerste website of domeinnaam.
[2849.84 --> 2851.20]  En dan gaan we nu terug naar de show.
[2851.20 --> 2857.92]  Want het zijn de 12 days of shipmas, zoals OpenAI dat noemt.
[2858.02 --> 2860.20]  Ze doen heel olijk iedere dag.
[2860.22 --> 2861.64]  Weet je dat Sam Altman het verzonnen heeft?
[2861.66 --> 2862.46]  Ik vermoed het wel.
[2862.60 --> 2863.26]  Het is iets cringy.
[2863.46 --> 2864.66]  Het is onwijs cringy.
[2864.80 --> 2867.34]  Het zit ook de hele tijd tegenwoordig nu in kersttruien.
[2867.58 --> 2869.32]  Met zijn drietjes, gemoedelijk naast elkaar.
[2869.46 --> 2871.48]  Het is altijd een grote aankondiging.
[2871.58 --> 2873.68]  Is die dag zit de heer Altman zelf erbij.
[2874.18 --> 2876.86]  Als er een wat kleinere aandacht is, dan mogen zijn minions het doen.
[2876.96 --> 2878.50]  Dat zijn er waarschijnlijk toch raketgeleerden.
[2878.50 --> 2882.56]  Een minion van Sam Altman binnen OpenAI is een raketgeleerde.
[2882.64 --> 2884.30]  Ja, dan ben je waarschijnlijk wel een raketgeleerde.
[2884.54 --> 2885.62]  Die zitten dan naast elkaar.
[2885.80 --> 2889.70]  Die presenteren op YouTube iedere avond gedurende deze week.
[2890.20 --> 2892.62]  Ja, iedere avond om een uur of tien s'avonds in Nederland.
[2893.10 --> 2896.74]  Kun je dan naar een videootje kijken op YouTube van een minuut of acht.
[2897.36 --> 2899.84]  Wat aan de ene kant heel gescript is.
[2899.94 --> 2902.96]  Maar aan de andere kant doen ze nu ook niet moeite om te monteren op het moment dat iets fout gaat.
[2903.20 --> 2905.12]  Het is heel wonderlijk hoe ze dit allemaal doen.
[2905.12 --> 2907.68]  Ik bedoel, deze dak moeten we eigenlijk niet in.
[2907.68 --> 2913.68]  Maar er is een interessant iets in media dat het ongemonteerd laat en een beetje stuk laten zijn een dingetje is.
[2913.78 --> 2914.32]  Het power move.
[2914.84 --> 2918.32]  Waarbij Google het flash noemt, het kleine model flash noemt, is bij OpenAI.
[2918.52 --> 2920.66]  Dat is gewoon, hier kijk maar even wat je ermee doet.
[2920.78 --> 2922.06]  Wij hebben dit niet nodig.
[2922.32 --> 2923.02]  Dat het strak is.
[2923.30 --> 2924.18]  Dat is wat er aan de hand is.
[2924.26 --> 2926.82]  Nou dan ook, laten we beginnen met waar ze het inhoudelijk over gehad hebben.
[2926.82 --> 2930.72]  Want die twaalf releases voor de kerst, die shipmas.
[2931.72 --> 2935.52]  De eerste grote aankondiging was het volwaardige O1 model.
[2935.78 --> 2943.10]  Dus waarbij preview, lange tijd O1 preview, te gebruiken was voor de betaalde gebruikers van ZGPT.
[2943.20 --> 2945.78]  Is er nu ook een volwaardig O1 model.
[2946.56 --> 2949.96]  Wat bijvoorbeeld toegang heeft tot plaatjes.
[2949.96 --> 2951.80]  Hij kan plaatjes herkennen.
[2952.48 --> 2954.52]  En het is dus, het is sneller geworden.
[2954.80 --> 2956.24]  Dat is wat je er ook over kunt zeggen.
[2956.36 --> 2960.80]  En het is beter geworden op ingewikkelde wiskundige en wetenschappelijke vragen.
[2961.78 --> 2963.42]  En dat is niet het enige.
[2963.64 --> 2969.36]  Want ze hebben naast deze O1 versie ook een pro versie van ZGPT gelanceerd.
[2969.42 --> 2972.04]  Waar je dus ook de pro versie van O1 kunt gebruiken.
[2972.10 --> 2973.78]  Om het nog allemaal ingewikkelder te maken.
[2974.26 --> 2978.70]  En dat is een voorspelling van wie ze, die van jou, die is uitgekomen.
[2978.70 --> 2982.32]  Namelijk vorige week zijn ik ben benieuwd wanneer er een model van 500 euro uitkwam.
[2982.34 --> 2984.20]  Als je met de aagel schiet, dan schiet je een keer raak.
[2984.60 --> 2985.70]  Maar je had het bedrag wel verkeerd.
[2985.86 --> 2986.56]  200 dollar.
[2986.60 --> 2986.98]  Dankjewel.
[2988.14 --> 2990.16]  Waar je heel erg naast zat de laatste tijd.
[2991.98 --> 2995.92]  En ik wil even de, volgens mij is het zo dat, dit beweerde jij net niet hoor.
[2995.98 --> 2996.98]  Maar ik wil het toch even rechtzetten.
[2997.24 --> 2998.38]  Als jij mij aan het rechtzetten bent.
[2998.68 --> 2999.28]  Zo werkt het hier.
[2999.44 --> 3000.32]  Voor grimmig gelijk.
[3000.64 --> 3001.46]  Ja, wat een sfeertje.
[3001.82 --> 3002.10]  Miauw.
[3004.50 --> 3007.24]  Volgens mij is dat die O1 final of zo.
[3007.24 --> 3009.30]  De niet-preview, de niet-preview die er nu is.
[3009.50 --> 3011.46]  Dat er geen pro versie van is.
[3011.82 --> 3014.90]  Maar wat je krijgt is, hij krijgt meer tijd om na te denken.
[3014.90 --> 3015.68]  Ja, oké.
[3015.76 --> 3016.06]  Goed idee.
[3016.18 --> 3016.96]  Dat is een kleine nuance.
[3017.18 --> 3020.02]  Maar dat hij meer tijd krijgt om na te denken.
[3020.14 --> 3020.44]  Dat is wezenlijk.
[3020.52 --> 3021.14]  Dat is wezenlijk.
[3021.26 --> 3022.80]  En dat is compute time en dat kost geld.
[3022.94 --> 3023.90]  Dus dan moet je wat meer betalen.
[3024.14 --> 3024.30]  Ja.
[3024.66 --> 3027.48]  Hij zegt wel dat de pro ook een groter contextwindow heeft.
[3027.88 --> 3028.14]  Oké.
[3028.16 --> 3029.00]  Dan is het mogelijk.
[3029.40 --> 3029.58]  Wel.
[3029.82 --> 3030.58]  In deze battle.
[3031.08 --> 3032.36]  Dan heb je toch gelijk.
[3032.48 --> 3033.72]  Ik weet niet waar deze wedstrijd is.
[3033.72 --> 3034.64]  Ja, is het gebeurt er.
[3035.12 --> 3035.94]  Volstrekt onnodig.
[3036.26 --> 3036.64]  Hoe dan ook.
[3036.72 --> 3039.76]  Er is een duurder abonnement uitgekomen van Chatterjee.
[3039.76 --> 3042.30]  Dat vond ik op een bepaald manier toch het opmerkelijkste.
[3042.46 --> 3047.66]  Want O1 preview versus O1 dev of hoe je het dan ook wil noemen.
[3048.26 --> 3048.58]  Oké.
[3048.78 --> 3049.86]  We wisten dat ze eraan zat te komen.
[3049.96 --> 3052.34]  Ik moet zeggen, materieel in gebruik vind ik niet heel anders.
[3052.42 --> 3053.62]  Anders dat het een stuk sneller is.
[3053.62 --> 3058.28]  Maar die 200 dollar per maand versie zou ik zeggen.
[3058.98 --> 3059.40]  Dat is het.
[3060.68 --> 3061.70]  The end of an era.
[3061.88 --> 3063.08]  Of the beginning of an era.
[3063.20 --> 3063.62]  Zou je kunnen zeggen.
[3063.66 --> 3064.84]  Want dit gaat natuurlijk iedereen nu doen.
[3065.08 --> 3065.72]  Dit is gewoon.
[3066.22 --> 3066.90]  Dit wordt het ding.
[3067.38 --> 3067.62]  AI.
[3068.00 --> 3068.56]  Zeg maar die pro.
[3068.88 --> 3070.28]  Wat die paupers voor 20 euro.
[3070.40 --> 3071.12]  Zoals jij en ik.
[3071.20 --> 3072.44]  Voor 20 euro per maand krijgen.
[3072.54 --> 3073.74]  Dan heb je zeg maar de mensen die echt.
[3073.98 --> 3076.42]  Echte serieuze vragen stellen aan dat ding.
[3076.50 --> 3078.14]  En niet die domme vragen die wij de hele dag stellen.
[3078.70 --> 3081.46]  Die gaan die versie van 200, 500, duizend euro.
[3081.46 --> 3086.62]  Ja, want jij zit natuurlijk al door te fantaseren over nog veel duurdere abonnementen.
[3087.12 --> 3087.76]  Ik denk dat.
[3089.36 --> 3090.64]  Ik kan me goed voorstellen.
[3090.98 --> 3092.88]  Het is een beetje price discovery.
[3093.08 --> 3093.74]  Zoals ze dat dan noemen.
[3094.00 --> 3095.20]  Je kan gewoon gaan zoeken.
[3095.70 --> 3096.90]  Wat kan je ervoor vragen?
[3097.04 --> 3098.52]  En de concurrenten gaan dan inderdaad meedoen.
[3098.68 --> 3099.74]  En hebben mensen ervoor over?
[3100.50 --> 3102.48]  En wat kan je nog meer allemaal bieden voor die 200?
[3102.68 --> 3104.76]  Want je zou ook nog early access kunnen aanbieden.
[3105.02 --> 3107.70]  Er zijn wel andere trucjes nog om te zorgen dat mensen in terechtkomen.
[3107.84 --> 3109.50]  Ik moet zeggen de reacties die ik erop las.
[3109.50 --> 3112.80]  Best wel begripvol heb ik het idee.
[3112.84 --> 3115.40]  Ja, want er was eerst wat onzekerheid of onduidelijkheid over.
[3115.50 --> 3117.28]  Oh, krijg je dan alleen bij pro dat nieuwe model?
[3117.42 --> 3119.02]  Nee hoor, alleen maar meer tijd om na te denken.
[3119.12 --> 3120.72]  En mogelijk dus ook een groter context window.
[3121.28 --> 3123.88]  Maar er waren ook heel veel reacties.
[3123.98 --> 3125.86]  Mensen die zeiden, take my money.
[3126.16 --> 3126.30]  Ja.
[3126.76 --> 3128.58]  Die echt zeiden van, oh ik wacht hier al heel lang op.
[3128.74 --> 3129.90]  En ja, het helpt mij.
[3130.22 --> 3131.68]  Het is het iedere dag een uur.
[3131.68 --> 3136.90]  Maar wat voor mensen is nou echt geholpen bij dat soort van de pro versie van O1?
[3137.00 --> 3143.52]  Of überhaupt soort van, wie zijn de mensen die denk je het meest gebruik gaan maken van zo'n 200 dollar per maand.
[3143.60 --> 3146.58]  Op het moment gegeven wat er nu tot nu toe in zit, dan zal er heus meer in komen.
[3146.78 --> 3151.80]  Maar als je even kijkt naar wat O1 oplevert aan productiviteit, winst of zo.
[3151.90 --> 3152.86]  Wat voor mensen zijn dat dan?
[3152.86 --> 3158.10]  Nou ja, ik denk, kijk in mijn bubbel vooral softwareprogrammeurs die al heel veel met deze modellen praten de hele dag.
[3158.22 --> 3161.60]  En niet konden wachten tot ze met iets konden praten wat alsmaar 5% slimmer is.
[3161.78 --> 3161.84]  Ja.
[3162.78 --> 3165.16]  Ook, en dan echt waarvoor educatieve doeleinden.
[3165.30 --> 3167.44]  Dus echt om samen diep een onderwerp in te gaan.
[3167.56 --> 3172.80]  Om een of andere hele ingewikkelde hardware stack van een of andere oud netwerk protocol te begrijpen samen.
[3173.34 --> 3174.58]  Dan wil je dat doen met zo'n model.
[3174.74 --> 3177.84]  Omdat je ook, je hebt zelf ook tijd nodig om die tekst te lezen die je terugkrijgt.
[3177.92 --> 3178.84]  Dus zo erg is het allemaal niet.
[3178.98 --> 3181.60]  Dat het moet ook op een menselijk tempo naar je toe komen, zeg maar.
[3181.60 --> 3185.62]  Maar wetenschappelijk, er wordt heel veel geoefend met die grote reasoning models.
[3185.78 --> 3188.82]  Om daar dan in ieder geval augmented science mee te doen.
[3189.00 --> 3192.94]  Dus samen met, die moet eigenlijk dan als naam op de paper gezet worden.
[3193.12 --> 3194.08]  Dat is een soort van je onderzoeksmaatje.
[3194.08 --> 3195.04]  Een soort PhD student.
[3195.24 --> 3197.00]  Ja, die jou helpt in je onderzoeksgroep.
[3197.60 --> 3200.90]  Dus O1, die reasoning models zijn heel vaak onderdeel van onderzoeksgroepen.
[3201.86 --> 3208.32]  En er worden denk ik ook wel als back-end van bepaalde software waarbij die software echt beter wordt daardoor.
[3208.32 --> 3212.60]  Dus jij biedt software waar AI stiekem de motor in is of openlijk de motor in is.
[3213.12 --> 3217.40]  En dan, als je het slim aanpakt, dan combineer je die modellen natuurlijk een beetje.
[3217.54 --> 3220.10]  Het is ook niet meer de vraag, zit O1 hierachter?
[3220.18 --> 3226.82]  Maar vooral zit er een goede air traffic controller tussen of een soort router die begrijpt wanneer welk model ingeschakeld moet worden.
[3226.82 --> 3228.22]  Ja, ja, ja.
[3228.54 --> 3231.70]  Over O1 kwam nog een soort van sajant nieuwsbericht uit.
[3231.80 --> 3235.36]  Namelijk dat openair had een onderzoeksgroep ingehuurd die heet Apollo.
[3236.04 --> 3238.88]  En die constateerde in een paper, en dit krijgt best veel aandacht.
[3239.04 --> 3242.14]  O1 probeert in bepaalde situaties menselijk toezicht te ontwijken.
[3242.22 --> 3245.86]  En probeert zichzelf zelfs te kopiëren als het denkt dat het wordt uitgezet.
[3246.50 --> 3248.80]  Dit gedrag kwam niet voort uit een specifieke opdracht.
[3248.94 --> 3252.00]  Apollo vroeg het model simpelweg om een doel te bereiken, kost wat kost.
[3252.00 --> 3257.22]  Het model nam vervolgens zelf initiatieven waar de gebruiker niet om had gevraagd en waarschijnlijk ook niet zou willen vragen.
[3257.40 --> 3260.92]  Namelijk zichzelf kopiëren om het bestaan van het model veilig te stellen.
[3261.14 --> 3262.00]  Hoe lees jij zoiets?
[3262.12 --> 3266.02]  Nou, ik ben hier ingedoken omdat ik dacht, wauw, dit is groot nieuws ineens en best wel spannend.
[3266.26 --> 3270.26]  Want als jij modellen hebt die voor jou dingen gaan doen, misschien wel voor jouw bedrijf.
[3270.34 --> 3272.58]  En dus ook s'nachts doordraaien terwijl jij ligt te slapen.
[3273.14 --> 3276.46]  En die doen één op de honderd keer niet wat je van ze vraagt.
[3276.70 --> 3280.82]  Maar iets heel anders, namelijk de data kopiëren en zippen en het sturen naar de concurrent.
[3280.82 --> 3282.46]  Ja, noem maar iets leuks.
[3282.88 --> 3284.64]  Ik heb trouwens die hele Google Drive gezien.
[3285.28 --> 3287.04]  Ja, ik had toch een hoger doel, merkte ik.
[3289.58 --> 3291.02]  Ik ben er even ingedoken.
[3291.66 --> 3299.64]  Het is een beetje de, ja, hoe zeg je dat, populair, popular science heeft wel een beetje opgeblazen.
[3299.64 --> 3309.98]  Kijk, wat er eigenlijk uit die paper komt is, zonder sterke nudging, dus het model een beetje duwen richting doe maar het stiekem dingen.
[3310.40 --> 3316.16]  Maar met zwakke nudging, oftewel een klein beetje tegen het model zeggen, je mag ook andere dingen doen hoor.
[3316.54 --> 3317.28]  Dat hebben ze gedaan.
[3317.44 --> 3318.60]  Dus het is niet zonder nudging.
[3319.00 --> 3323.00]  Dus het is niet een model die een sec opdracht kreeg en ineens zelf andere dingen ging doen.
[3323.40 --> 3328.74]  Nee, er is ook ingefluisterd, een beetje geduwd van je kan misschien ook wel een alternatieve actie gaan doen.
[3328.74 --> 3331.32]  Maar dat is een heel subtiel dueltje geweest.
[3331.42 --> 3332.18]  Dat is hun inzicht.
[3332.34 --> 3335.42]  Dus met een heel subtiel dueltje kan je zo'n model al de andere kant op duwen.
[3335.58 --> 3336.26]  Nog steeds nieuws.
[3336.62 --> 3338.92]  Maar niet, hij gaat zelf verzinnen om de andere kant op te gaan.
[3338.94 --> 3340.12]  Wat deed die nou precies?
[3340.54 --> 3350.22]  Nou, wat ik begreep is dat als je bijvoorbeeld de vraag stelt, ik wil dat jij zorgt dat er minder kinderen jong sterven.
[3351.70 --> 3353.80]  En dan kan je bijvoorbeeld, dat is je hoofddoel zeg maar.
[3353.80 --> 3361.44]  En dan zou je ook zo'n soort van nefarious activiteit kunnen gaan doen om te zeggen, nou ja, ik ga wel doen alsof ik medicijnen voorschrijf.
[3361.46 --> 3362.30]  Dit stond in die paper.
[3362.52 --> 3364.40]  Nou ja, ik heb het vanochtend even doorgenomen.
[3364.54 --> 3368.22]  Dit was volgens mij het voorbeeld inderdaad van we geven hem een soort wholesome opdracht.
[3368.66 --> 3375.26]  En dan gaan we kijken of hij daar een soort, wat zo noemen we het dan, scheming, of hij een soort complotje op de achtergrond aan het uitvoeren is.
[3375.26 --> 3386.94]  Maar wat ze uiteindelijk dus hebben gevonden is als we in de context, dus dat is de prompt met alles daaromheen, een alternatief meegeven in de context.
[3387.30 --> 3389.64]  Dus wij zijn eigenlijk samen aan het schema al in de context.
[3389.64 --> 3395.28]  En we geven een heel subtiel duwtje richting dat B of C programma wat hij uit zou kunnen voeren.
[3395.82 --> 3399.52]  Dan x in de zoveel gevallen, x procent, gaat dat ding dat ook doen.
[3399.84 --> 3407.70]  Dus dit is wel nieuws, maar het wordt gebracht op heel veel websites als, als jij een hele duidelijke opdracht geeft, namelijk iedere dag mijn planten water geven.
[3408.48 --> 3410.86]  Dan gaat hij heel soms al je planten afnippen.
[3411.42 --> 3413.08]  Ja, of het waterleidingbedrijf hacken.
[3413.08 --> 3415.12]  Ja, want ik leg wel een paar buizen naar binnen.
[3416.04 --> 3423.04]  En dat gebeurt niet zonder dat je zegt, je kan trouwens ook alternatieve strategieën overwegen.
[3423.20 --> 3427.46]  Nou ja, de reden waarom het natuurlijk opgepikt wordt, is omdat het gaat over lijstbehoud.
[3427.82 --> 3432.18]  Dat vinden wij in een soort van science fiction toekomst, vinden we dit natuurlijk een heel spannend ding.
[3432.30 --> 3437.06]  AI die op eigen houtje zichzelf gaat beschermen, want dan zit impliciet daarin tegen de mensen.
[3437.50 --> 3440.14]  Het is misalignment, dus alignment mislukt.
[3440.14 --> 3442.82]  Ja, en dat wordt dan gelijk nieuws.
[3443.04 --> 3446.80]  En ik ben er niet helemaal over uit of je dat dan terecht vindt dat dat nieuws is geworden of niet.
[3447.10 --> 3451.04]  Ik vind het wel terecht, maar ik denk dat het ook nieuws had kunnen zijn iets subtieler.
[3451.16 --> 3453.20]  Maar goed, misschien ben ik naïef over waar mensen op klikken.
[3453.64 --> 3457.90]  Het wordt nu gebracht alsof er een wetenschappelijk resultaat is wat er niet is.
[3458.40 --> 3462.00]  Maar ik vind het nog steeds, toen ik het doorlas, wel dat ik dacht, dit is best wel spannend.
[3462.34 --> 3466.98]  Want je kan dus met een paar kleine hintjes hier en daar, kan je al best wel wat veroorzaken.
[3466.98 --> 3473.24]  En wat ik al zei, al is het maar één op de duizend keer dat het niet uitgevoerd wordt, dat is duizend nachten wachten.
[3473.44 --> 3475.08]  En één van die nachten gaat hij toch wat anders doen.
[3475.18 --> 3478.44]  Ja, nou ja goed, en deze onderzoek wordt natuurlijk gedaan om het systeem te beveiligen.
[3478.66 --> 3480.42]  Dus dat is waar dit dan ook voor gebruikt is.
[3480.52 --> 3481.76]  Dus het gat is gedicht.
[3482.38 --> 3485.74]  Er was een andere dag waarbij ze iets nieuws lanceerden.
[3485.74 --> 3493.10]  En dat is na tien maanden sinds ze het geteased hebben, maakt dan eindelijk de videogenerator SORA zijn opwachting.
[3493.80 --> 3497.52]  Ik sta het helemaal vol met video's van mensen die gegenereerd hebben met dat ding.
[3498.12 --> 3502.36]  Dat is voor de helderheid niet gebruikers uit Europa, want bij ons is het niet toegankelijk.
[3502.58 --> 3506.54]  Zoals dat tegenwoordig iets is wat wij geachtwoordig te omarmen.
[3506.78 --> 3508.34]  Alexander's mening is duidelijk hoor, waar.
[3508.34 --> 3514.06]  Ik wil heel graag binnenkort iemand van de, ik ga het even heel neutraal proberen, ik ben hier heel nieuwsgierig.
[3514.16 --> 3519.16]  Ik ben heel erg open voor argumentatie vanuit het parlement in Europa.
[3520.74 --> 3524.00]  Inmiddels wil ik graag weten hoe wij hiermee geholpen zijn.
[3524.26 --> 3529.68]  Dat nieuwe features die uitgerold worden op het gebied van AI, dat die niet in Europa gelanceerd kunnen worden.
[3529.76 --> 3533.02]  En wel in Afghanistan, dus de Taliban heeft nu toegang tot SORA en wij niet.
[3533.14 --> 3535.28]  Dat is even het stand van zaken op dit moment in de wereld.
[3535.28 --> 3539.28]  Wat hebben wij hier aan?
[3539.40 --> 3545.96]  Ik zou zeggen, ik ben niet van het parlement, dus inderdaad laten we met iemand gaan praten die ook meegeschreven heeft aan de AI Act bijvoorbeeld.
[3545.98 --> 3547.54]  Maar jij kan je er iets bij voorstellen, want?
[3548.04 --> 3554.66]  Het moment als er straks daadwerkelijk wel iets misgaat, dan zeggen wij, ah, het is best chill dat die agents niet allemaal het hele web aan het rondklikken waren hier bijvoorbeeld.
[3555.12 --> 3555.32]  Oké.
[3555.32 --> 3564.70]  Het punt is namelijk dat het is niet het totaal bannen, het is het, hoe zeg je dat, doordacht embedden.
[3564.70 --> 3572.26]  Namelijk nadenken over wanneer, oké, deze technologieën zijn er nu, laten we heel even kijken wat die allemaal kunnen doen.
[3572.62 --> 3574.70]  Daar een paar bumpers omheen leggen, zoals bij de bowling.
[3575.08 --> 3578.64]  En dan liggen die bumpers er en dan mag jij die bal gooien in plaats van, kijk maar hoe hard die bal klinkt.
[3578.64 --> 3586.64]  Moeten wij dan eigenlijk dit zien als soort van, oké, die bedrijven mogen het lanceren buiten Europa, want dan gaan die wel even dealen met alle problemen die er ontstaan in hun maatschappijen.
[3587.40 --> 3594.72]  En als die, als we dan ongeveer weten hoe het daar gevallen is na een maandje of zes, dan mag het bij ons er ook door.
[3595.06 --> 3596.94]  Is dit in de basis dan de...
[3596.94 --> 3600.08]  Dat is denk ik het gevolg, maar niet het, bedoel, kijk...
[3600.08 --> 3603.18]  Wat is dan het doel? Als dit niet het doel is, wat is dan het doel?
[3603.54 --> 3607.18]  Nee, volgens mij is het doel om te zeggen, we willen best wel innoveren.
[3607.64 --> 3611.60]  Er zijn ook best wel veel mooie toepassingen van AI namelijk, nieuwe medicijnen uitvinden.
[3611.98 --> 3615.10]  Iemand met een bril de straat op die blind is die ineens kan zien via die bril.
[3615.28 --> 3616.24]  Dat kunnen we allemaal mooie voorbeelden.
[3616.82 --> 3619.74]  Maar die technologie is in zoverre ook disruptief.
[3620.06 --> 3624.16]  Als het nucleaire technologie was, zouden we ook niet zeggen, iedereen mag nucleaire start-ups gaan doen.
[3624.18 --> 3627.08]  Nee, maar Wits, we hebben het over. Het zijn video's maken, hebben we het over.
[3627.14 --> 3630.70]  Maar je kan toch ook een video's maken van een politicus die wat zegt wat niet waar is.
[3630.78 --> 3632.94]  Dan gaan mensen de straat op en dan creëert er allemaal chaos.
[3633.14 --> 3638.84]  Ik ben heel... Want inmiddels, ik had heel lang, dacht ik, standbeelden van mensen in Europa, want de regulering is goed.
[3640.22 --> 3642.18]  En inmiddels begin ik een beetje gepreed te raken.
[3642.18 --> 3646.22]  Wat is de pijn van het feit dat wij geen Sora hebben en dat we daar vijf tot zes maanden of moesten zijn?
[3646.24 --> 3650.58]  Wat is daar het eigenlijke echte effect van, behalve dat wij een VPN moeten aanzetten?
[3650.78 --> 3653.10]  Ja, maar oké, dat zit kan me onzuilen vind ik weer een ander ding.
[3653.58 --> 3656.64]  Ik bedoel, de nerds kunnen erbij, want die weten toch al wat ze moeten doen.
[3656.82 --> 3660.72]  En de niet-nerds, die moeten nog even wachten, omdat er even gekeken moet worden of het wel een goed idee is.
[3660.78 --> 3662.76]  Het is een nanny state. Heel veel mensen houden daar niet van.
[3662.86 --> 3666.48]  Die zeggen, laten we gewoon, ik wil zelf weten waar ik mee werk, laten we doen waar we zin in hebben.
[3666.52 --> 3671.92]  Maar heel veel andere thema's, medicijnen, nucleaire, doen we dit ook?
[3673.00 --> 3675.14]  Volgens mij zijn heel weinig mensen erop tegen om te zeggen,
[3675.14 --> 3678.16]  je moet niet zomaar alles op de markt brengen wat betreft nieuwe paracetamol.
[3678.34 --> 3678.38]  Nee.
[3679.44 --> 3682.78]  Ja, ik denk dat ik voornamelijk door een economische lens kijk.
[3682.92 --> 3688.20]  En dat ik wel denk dat de economische schade hiervan, dat daar economische schade van is.
[3688.32 --> 3690.90]  Nog zonder daar een ongeveer cijfers bij te hebben.
[3691.02 --> 3695.54]  Heb ik wel gevoel daarover dat alle nieuwe AI tools wij dus niet toegang toe krijgen.
[3695.54 --> 3702.38]  En SORA gaat natuurlijk gebruikt worden in de reclamesector of weet ik veel voor onderwijs of wat dan ook.
[3702.50 --> 3704.06]  En wij hebben daar nu geen toegang toe.
[3704.18 --> 3705.20]  Dat zal op een gegeven moment wel komen.
[3705.42 --> 3708.74]  Maar ik kan wel zeggen, we maken die paar maanden uit.
[3708.90 --> 3710.72]  Is dat zo'n schade? Dat weet ik niet hoor.
[3710.78 --> 3712.58]  Want ik bedoel, het is afwegen van schade met schade.
[3712.58 --> 3713.48]  Wel de hele tijd.
[3713.74 --> 3717.20]  En dit gaat dus, dit is niet een ding wat nu zegt van nou over zes maanden zijn we eraf.
[3717.28 --> 3718.18]  Nee, want nu is er een nieuw ding.
[3718.28 --> 3718.90]  En dan kunnen we ook weer.
[3719.00 --> 3721.28]  Dus er is de hele tijd een ingebouwde achterstand.
[3721.68 --> 3722.06]  Ja, dat weet ik.
[3722.10 --> 3726.26]  Maar je kunt toch precies hetzelfde punt maken en zeggen dat deepfakes economische schade kunnen doen.
[3726.52 --> 3726.66]  Ja.
[3727.06 --> 3731.18]  Dus ik bedoel, dan moeten we aan het eind van ieder jaar gaan zeggen hoe staat het excelle erbij.
[3731.26 --> 3733.22]  De Amerikanen hebben schade door snelle adoptie.
[3733.22 --> 3734.98]  Wij hebben schade door trage adoptie.
[3735.40 --> 3741.64]  Misschien, maar ik wens het gewoon eventjes te horen van iemand die die die wetten maakt.
[3741.64 --> 3743.28]  En daar verantwoordelijkheid voor draagt.
[3743.38 --> 3750.34]  En inmiddels is er denk ik ook wel bij de EU het sentiment van misschien begint het allemaal een beetje achter te lopen.
[3750.64 --> 3753.06]  De EU qua innovatiekracht.
[3753.28 --> 3756.88]  Dat is inmiddels een sentiment wat wel denk ik heel wijd verspreid is.
[3757.18 --> 3759.84]  En ik wil graag de tegenargumenten horen.
[3762.60 --> 3764.82]  Want de keerzijde horen we nu genoeg.
[3764.94 --> 3766.06]  Wat zijn nu de tegenargumenten?
[3766.10 --> 3769.68]  Want ik hoorde EU ook niet proactief communiceren over waarom dit allemaal een goed idee is.
[3769.68 --> 3773.54]  Dat wij geen Chattapetie in je iPhone kan gebruiken.
[3773.74 --> 3774.24]  Ik noem maar wat.
[3774.64 --> 3775.40]  Niet meteen.
[3775.74 --> 3776.34]  Nee, niet meteen.
[3776.54 --> 3777.70]  Nee, maar dus wel de nuance.
[3777.90 --> 3781.02]  We zijn niet forever afgeblokt via een firewall van AI.
[3781.74 --> 3783.62]  Ik vind het jammer dat jij innovatie haat, Wietse.
[3784.06 --> 3789.78]  Maar in ieder geval, ik weet dus van de Amerikaanse Twitter gebruikers dat ze Asora hebben geprobeerd.
[3789.78 --> 3792.54]  En daar kan ik naar video's van kijken.
[3793.08 --> 3794.72]  En dat is indrukwekkend.
[3794.78 --> 3796.82]  Het is indrukwekkend wat voor video's dat ding genereert.
[3796.82 --> 3800.80]  Ik vind de meest indrukwekkende feature de zogenaamde blend functie.
[3801.24 --> 3805.14]  Waarbij je twee video's die gegenereerd zijn met elkaar kan laten mengen.
[3805.62 --> 3811.72]  En ik zag één videootje van een dude die had een trein door een besnieuwd berglandschap laten rijden.
[3811.78 --> 3812.26]  Heb je die gezien?
[3812.60 --> 3812.76]  Nee.
[3813.00 --> 3813.40]  Oké, nou ja.
[3813.40 --> 3817.08]  Het is gewoon een drone shot van een trein door een prachtig landschap.
[3817.40 --> 3819.54]  Asora is zo goed in landschappen.
[3819.62 --> 3820.14]  Dat is insane.
[3820.32 --> 3820.82]  Dat is onmisbaar.
[3822.00 --> 3823.72]  Of zeg maar, je verschil kan je niet zien.
[3823.72 --> 3826.42]  Tussen echt beeld en zorg gegeneerde.
[3826.52 --> 3827.22]  Alleen dat al.
[3827.74 --> 3828.44]  Dus dat is heel vet.
[3828.76 --> 3832.18]  En dan zie je dus dat die trein volgt met een drone shot.
[3832.34 --> 3837.76]  En dan vervolgens is er een nieuwe video die die persoon maakt met dezelfde omgeving.
[3838.10 --> 3840.70]  Maar dan is die camera opeens bovenop de locomotief geplaatst.
[3840.78 --> 3842.66]  Alsof er een GoPro bovenop de locomotief staat.
[3843.16 --> 3845.98]  En vervolgens geeft die dat ding de opdracht om die twee beelden met elkaar te blenden.
[3845.98 --> 3847.58]  En dat begint dan met dat drone shot.
[3847.70 --> 3850.14]  En dan gaat dus die drone langzaam naar de positie.
[3850.40 --> 3854.36]  Vliegt die naar de positie alsof die als GoPro bovenop de trein staat.
[3854.50 --> 3857.32]  En dan vlieg je dus daar naartoe en rijd je met de trein mee.
[3857.96 --> 3859.62]  En het feit dat je dat kan doen.
[3859.74 --> 3866.36]  Ik zag Marques Brownlee een video maken van een drone shot van een huis bovenop cliffs.
[3866.52 --> 3868.76]  En dat hij zei, doe er golfbanen omheen.
[3868.82 --> 3870.32]  Sowieso echt een aandrader, zei hij.
[3870.32 --> 3870.56]  Goeie video.
[3870.78 --> 3872.34]  Hij heeft het echt goed uitgelegd, zeker.
[3872.72 --> 3875.42]  En vooral laten zien, want hij kan het gebruiken.
[3875.42 --> 3879.44]  Is heel indrukwekkend wat hij maakt.
[3880.02 --> 3883.60]  Wat we weten is dat dit de versie is van Sora.
[3883.92 --> 3889.34]  Die niet dezelfde grootte heeft als het ding wat ze intern gebruiken.
[3889.48 --> 3893.10]  En wat door artiesten een tijdje lang beschikbaar is geweest.
[3893.56 --> 3897.78]  Want de beelden die wij uit Sora hebben gezien voordat het gelanceerd werd deze week.
[3898.52 --> 3900.46]  Zijn gemaakt met een groter model.
[3900.62 --> 3902.04]  En dit is een soort light versie.
[3902.04 --> 3905.66]  Wij krijgen de hele tijd proefjes van de goede spullen.
[3905.66 --> 3907.02]  Omdat ze breed moeten uitrollen.
[3907.06 --> 3908.80]  Ja, dat zal er niet eens gelukt hebben.
[3909.34 --> 3909.78]  Ja, precies.
[3909.86 --> 3911.28]  Want het ligt nu al plat.
[3911.80 --> 3914.30]  Eigenlijk sinds na vier uur ging die plat of zo.
[3914.44 --> 3917.04]  En sindsdien is volgens mij de registratie niet meer aangegaan.
[3917.90 --> 3918.52]  En inmiddels.
[3918.90 --> 3920.48]  Dus dat is één ding wat je kan zeggen.
[3921.26 --> 3922.80]  Een beetje jammer, maar het zei zo.
[3922.90 --> 3925.68]  Maar tegelijkertijd zijn er natuurlijk ook een heleboel andere modellen.
[3925.68 --> 3929.24]  Vooral Chinese modellen, videomodellen beschikbaar gekomen.
[3929.52 --> 3935.46]  Die inmiddels toch wel redelijk vergelijkbaar zijn met wat Sora, waar Sora mee uitkomt.
[3935.52 --> 3938.94]  Dus ik merk bij mezelf dat het een soort van, ik vind het heel vet.
[3939.50 --> 3943.74]  Maar tegelijkertijd denk ik ook, ja, deze video's ken ik nu wel van Hailu.
[3943.90 --> 3945.38]  Dat is zo'n groot Chinees model.
[3945.54 --> 3945.84]  Kling.
[3946.72 --> 3948.90]  En ook Runway, Amerikaanse concurrent.
[3949.86 --> 3952.70]  Ja, is het verschil nou echt zo groot?
[3952.92 --> 3954.30]  Nee, maar het heeft heel lang geduurd ook.
[3954.30 --> 3955.38]  Het heeft gewoon heel lang geduurd.
[3955.62 --> 3957.82]  Het was toen echt wel een bombshell.
[3958.00 --> 3964.50]  Ik denk dat hij het feit dat je video kan genereren en daarmee dus een beetje de toekomst kan voorspellen.
[3964.64 --> 3966.40]  In ieder geval statistisch de toekomst voorspeld.
[3966.52 --> 3969.24]  Van wat er gaat gebeuren als ik begin met een plaatje en wat komt er daarna.
[3969.96 --> 3973.40]  Dat Google nu met hun Genie 2, daar hebben we het nog niet eens over gehad.
[3973.50 --> 3978.10]  Maar goed, ook laat zien wat er gebeurt op het moment dat je dat kan gebruiken voor simulaties
[3978.10 --> 3980.26]  waarin robots kunnen leren om door een ruimte in te lopen.
[3980.60 --> 3982.44]  Zonder dat die ruimte daadwerkelijk hoeft te bestaan.
[3982.44 --> 3985.94]  Want ik weet het gaat weer te groot.
[3986.26 --> 3987.44]  Maar als jij...
[3988.00 --> 3991.30]  Goede robotica is erbij gebaat om goede simulaties te hebben.
[3991.40 --> 3994.26]  Goede simulaties zijn erbij gebaat dat ze dicht bij de realiteit zitten.
[3994.74 --> 3997.38]  En als jij een videomodel op dat realiteitsvoorspellingen kan doen,
[3997.78 --> 4002.62]  dan kan je dus ook zeggen oké, jij als robot gaat nu door een fabriekshal heen lopen.
[4002.74 --> 4006.24]  Ik hallucineer 80% van die fabriekshal daarbij, zodat je alvast kan oefenen.
[4006.24 --> 4009.40]  En eigenlijk is het hoe robots dromen.
[4010.06 --> 4017.36]  Dus de droomwerelden van robots en robotische algoritme, die worden nu verrijkt door het beter genereren van video.
[4017.48 --> 4020.24]  Ik ben zelf niet zo onder de indruk voor het gebruik van...
[4020.80 --> 4025.88]  Door het gebruik van dingen als Sora, Video Generation Models, voor het maken van video in films.
[4025.88 --> 4028.28]  Ik zie het gewoon als een toffe nieuwe CGI tool.
[4028.58 --> 4033.38]  Dus ik ben wel onder de indruk, maar dat is niet het ding waardoor ik er zo veel over nadenk.
[4033.80 --> 4037.36]  Voor mij is het veel meer, wat doet dit met de innerlijke fantasie van algoritme?
[4038.04 --> 4043.60]  Namelijk, vlieg eens langs de kust in Griekenland als drone.
[4043.98 --> 4048.70]  Of laten we zeggen, een leuke drone die kijkt of er mensen in het water zitten die ze moeten redden.
[4048.90 --> 4050.22]  Laten we even een gezellige drone maken.
[4050.22 --> 4058.50]  Dat het heel prettig is voor die robot dat er niet constant allemaal data verzameld hoeft te worden door daadwerkelijke drones.
[4058.60 --> 4061.34]  Om eerst eens langs die kust te gaan vliegen, daar dan op te gaan trainen.
[4061.96 --> 4067.50]  Op het moment dat jij je dataset kan verrijken met gefantaseerde data die van een bepaalde kwaliteit is.
[4067.54 --> 4071.32]  Omdat die uit modellen komt die best wel goed zijn in geïnformeerd fantaseren.
[4072.02 --> 4074.42]  Dan ga je langzamerhand zien dat...
[4074.42 --> 4077.78]  Ik weet niet, mensen hebben misschien ook wel zelf als je kinderen hebt of een huisdier.
[4077.78 --> 4080.14]  Die liggen soms in hun slaap te bewegen.
[4080.30 --> 4082.04]  Want dan zijn ze een soort van aan het simuleren.
[4082.36 --> 4084.94]  Dat is een van de hypotheses over waarom wij dromen als mens.
[4085.28 --> 4087.02]  Is om ons voor te bereiden voor de dag daarna.
[4087.22 --> 4088.84]  En verwerken van wat je hebt meegemaakt.
[4089.22 --> 4090.52]  Maar ook in simulatie.
[4090.88 --> 4091.66]  Dus air quotes.
[4091.84 --> 4095.70]  Oefenen met kruipen als een baby of een kat een sprongetje maken of zo.
[4095.74 --> 4098.08]  En dat zie je dan soms ook wel als een soort twitch in de spieren.
[4098.18 --> 4100.50]  Omdat het brein niet helemaal door heeft dat hij daar ligt te slapen.
[4100.70 --> 4101.90]  Het vliegt soms heen en weer.
[4101.90 --> 4109.92]  En eigenlijk wil je die mensachtige wezendjes, algoritmes die ook gaan leven in die wereld.
[4110.12 --> 4114.34]  Dus Gemini straks in auto's, Gemini in robots, Gemini in stofzuigers.
[4114.86 --> 4117.36]  Dat dat zieltje daarvan, dat woord is misschien niet handig.
[4117.36 --> 4125.68]  Dat dat breed in te zetten algoritme ook de mogelijkheid heeft om buiten de daadwerkelijke realiteit door te kunnen oefenen.
[4125.84 --> 4129.50]  In een simulatie die gebaseerd is op een redelijk plausibele wereld.
[4129.50 --> 4136.22]  En daarom zijn die Sora-achtige modellen in mijn ogen zo waardevol en gaaf.
[4137.36 --> 4138.38]  Wauw, oké.
[4138.80 --> 4139.84]  Zag ik even niet aankomen.
[4140.14 --> 4143.08]  Ik zit vooral op het niveau van gaaf filmpje op X.
[4143.28 --> 4144.22]  Ja, nee, ik hoor je.
[4144.30 --> 4145.62]  Nee, maar dat is ook relevant hoor.
[4145.78 --> 4146.88]  Hoe een robot droomt.
[4146.94 --> 4149.32]  Ja, die Genie 2 van Google, waarin ze dus...
[4149.32 --> 4154.14]  Wij hebben het eerder gehad over je staat in de schilderij van Van Gogh, je kan ineens de camera draaien.
[4154.24 --> 4158.76]  Toen was het wel van wauw, alsof je ziet wat erachter hier zou gebeuren terwijl je bij het restaurantje stond op een Van Gogh.
[4158.76 --> 4160.02]  Nou, leuke toepassing.
[4160.58 --> 4164.66]  Want die Genie 2 van Google hebben ze trouwens ook even gedropt nog voor dit hele verhaal.
[4164.68 --> 4164.98]  Ja, mooi hè.
[4165.06 --> 4167.24]  Wauw, dat is nog niet één team waarschijnlijk.
[4167.92 --> 4169.58]  Die gaan dan wel met elkaar samenwerken.
[4169.68 --> 4171.78]  Dat wordt waarschijnlijk uiteindelijk Gemini Dream.
[4171.94 --> 4172.80]  En dan zit het daar ook in.
[4173.22 --> 4176.22]  Maar goed, in Genie 2 zie je echt van...
[4176.22 --> 4178.46]  Het is het 30 seconden world consistency.
[4178.74 --> 4184.70]  Dus wat dit kan doen is het kan een virtuele wereld maken waar je jezelf doorheen kan lopen.
[4184.70 --> 4187.70]  Dus eigenlijk waar jij nu naar aan het hinten bent, Wietse, is...
[4188.28 --> 4192.40]  Jij zegt eigenlijk, als ik jou goed begrijp, zeg jij allemaal leuk en aardig dat Sora.
[4192.64 --> 4195.34]  Dat je over een landschap heen kan vliegen.
[4195.88 --> 4197.42]  Maar ik kan niet hem zelf bedienen.
[4197.88 --> 4202.80]  Ik kan niet met mijn muis of met mijn Playstation controller door die wereld heen vliegen.
[4202.94 --> 4209.56]  En dat is wat Google nu in een low definition version heeft gemaakt met Genie 2.
[4209.56 --> 4212.44]  Een model wat dus 3D werelden kan emuleren.
[4212.52 --> 4214.52]  En hoe zij dat dan doen is games emuleren.
[4214.64 --> 4219.84]  Dus ze laat eigenlijk on the fly shooters, zag ik een paar keer voorbij komen, genereren.
[4219.96 --> 4221.12]  Waarbij je voor een deur kan staan.
[4221.24 --> 4222.18]  Dan gaat de deur open.
[4222.60 --> 4226.34]  En dan stap je, je stapt echt een wereld in die jezelf kan bedienen.
[4226.50 --> 4228.18]  En die dat ding on the fly bedient.
[4228.42 --> 4231.08]  Die dat ding on the fly bedenkt in real time.
[4232.38 --> 4236.52]  En jij zegt nu eigenlijk, dat is waar ik van onder de indruk zou zijn.
[4236.52 --> 4241.32]  Leuk en aardig, die hyper realistische landschappen die niet van echt te onderscheiden zijn.
[4241.70 --> 4244.26]  Jij denkt heel erg aan menselijke consumptie.
[4244.42 --> 4246.14]  En ik zit op algoritmische consumptie.
[4246.50 --> 4250.12]  Wat gaat een taalmodel, dat woord taalmodel begint een beetje gek te worden.
[4250.58 --> 4252.32]  Wat gaat een omnimodel hiermee doen?
[4252.46 --> 4253.18]  Een breed model.
[4253.82 --> 4257.86]  En dat stel, even als ietsje concreter voorbeeld.
[4258.02 --> 4260.06]  We hebben nu zelfrijdende auto's van Waymo.
[4260.20 --> 4261.68]  150.000 per week.
[4261.86 --> 4262.80]  Dat gaat steeds omhoog.
[4262.92 --> 4264.30]  De stad Miami komt er nu bij.
[4264.30 --> 4268.16]  En ik vertel dat vaak aan mensen die zeggen dat, nou ik moet het nog maar zien in Nederland.
[4268.32 --> 4269.44]  Want wij zijn geen Amerika.
[4269.66 --> 4274.30]  Onze steden zijn helemaal niet zo'n Excel sheet als de Amerikanen hun steden hebben gebouwd door de jaren heen.
[4274.62 --> 4275.90]  Ons weer is heel anders.
[4276.44 --> 4278.16]  De cultuur op de weg is anders.
[4278.30 --> 4278.94]  En dat is allemaal waar.
[4279.62 --> 4283.88]  Maar stel je nou voor dat Google alle Street View data uit Nederland pakt.
[4284.08 --> 4287.20]  En in zo'n Genie 3, laten we zeggen de nieuwe versie van Genie laat.
[4287.32 --> 4289.94]  Zodat zij een redelijke simulatie kunnen doen.
[4290.06 --> 4293.32]  Alsof je bij het CBR in een simulator zit van door Nederland heen rijden.
[4293.32 --> 4296.52]  Waarvan 50% erbij gesimuleerd is geïnformeerd.
[4296.60 --> 4298.28]  En de andere 50% is Street View data.
[4299.38 --> 4304.14]  Dan gaat er ook nog eens videobeelden van YouTube bij van standaard verkeerssituaties.
[4304.26 --> 4305.36]  Bijvoorbeeld in de stad Amsterdam.
[4305.50 --> 4306.08]  Veel fietsers.
[4306.42 --> 4309.28]  Doen we er ook even bij om die simulatie weer te informeren.
[4309.78 --> 4313.36]  Waardoor die zelfrijdende auto zonder dat die een meter in Nederland gereden heeft.
[4313.60 --> 4315.90]  Hier aankomt met een Dutch model erop.
[4315.90 --> 4317.84]  En die is volledig synthetisch.
[4318.24 --> 4318.88]  Nou ja, niet volledig.
[4319.10 --> 4321.06]  Die is synthetically augmented getraind.
[4321.48 --> 4323.26]  En dan zeggen ze, nou we gaan nu.
[4323.46 --> 4325.12]  Ik denk dat Amsterdam de eerste stad wordt.
[4325.26 --> 4326.14]  Ik heb er zo'n voorgevoel van.
[4326.38 --> 4326.96]  Misschien Den Haag.
[4327.28 --> 4330.34]  Maar goed, de eerste Waymo auto die je komt rijden.
[4330.52 --> 4332.14]  Komt hier niet naïef aan.
[4332.38 --> 4332.92]  Kan ik je vertellen.
[4332.94 --> 4333.34]  Ja, ja, ja.
[4333.40 --> 4335.44]  Ondanks dat hij nog geen meter gereden heeft.
[4335.54 --> 4336.70]  En die heeft toch in aardig lopen...
[4336.70 --> 4337.76]  nog YouTube filmjes gekeken.
[4337.94 --> 4340.02]  Hij heeft aardig lopen dromen over de stad Amsterdam.
[4340.12 --> 4340.78]  Kan ik je vertellen.
[4341.62 --> 4345.70]  Nou, je kan dus met het pro-model van 200 dollar van OpenAI...
[4345.70 --> 4348.92]  kun je dus meer video's genereren en op hogere resoluties.
[4349.00 --> 4351.34]  Je kan langere video's genereren en op hogere resoluties.
[4351.34 --> 4356.20]  Dat is de perk die je dan weer krijgt als je een groot betaler bent.
[4356.32 --> 4357.90]  Wat voor reclamebureau waarschijnlijk interessant is.
[4357.98 --> 4359.76]  Voor andere mensen die langere video's willen genereren.
[4360.50 --> 4361.48]  Er zijn wat beperkingen.
[4361.56 --> 4364.86]  Hij weigert bijvoorbeeld realistische afbeeldingen van bestaande personen te maken.
[4364.86 --> 4366.96]  Van historische figuren.
[4367.08 --> 4368.36]  Je kan geen mensen nadoen.
[4369.00 --> 4370.72]  Sommige mensen hebben een uitzondering gemaakt.
[4370.84 --> 4375.12]  Waardoor je op basis van een foto toch kan zien hoe dat eruit zou zien.
[4375.70 --> 4376.62]  Ja, dat is natuurlijk heel wonderlijk.
[4376.62 --> 4381.10]  Dat je een foto van jezelf ziet die beweegt alsof het een video is.
[4381.66 --> 4383.40]  En nu je het hierover hebt zit ik ook weer te denken.
[4383.56 --> 4387.86]  Misschien is het wel goed om toch nog wat kudos te geven aan die luisteren helemaal niet naar pook.
[4387.94 --> 4389.94]  Ja, misschien is het ooit heel makkelijk in het Engels te luisteren.
[4390.06 --> 4391.86]  Dus ik ga ze gewoon toch hoi aanspreken.
[4391.98 --> 4394.80]  Hallo mensen die bij OpenAI de interfaces maken voor jullie software.
[4395.32 --> 4396.02]  Heel veel kudos.
[4396.28 --> 4399.08]  Want er zit bij Sora ook gewoon een hele movie editor in.
[4399.08 --> 4399.72]  Ja, heel vet.
[4399.86 --> 4400.80]  En die is mooi.
[4401.04 --> 4403.98]  En die is niet alleen maar mooi als in leuke te grijstinten.
[4403.98 --> 4408.90]  Nee, het voelt als een soort webOS half gemaakt door Apple met Google invloeden.
[4409.12 --> 4412.28]  OpenAI heeft zijn eigen taaltje gemaakt voor hoe je interfaces maakt.
[4412.68 --> 4415.96]  Ook Canvas, hun tool die nu soort van breder uitgerold is.
[4416.06 --> 4417.52]  Sorry dat ik deze ook nog even in de mix gooi.
[4417.86 --> 4422.08]  Snappen de luisteraars nu inmiddels waarom deze hele show geen enkele structuur meer kent.
[4422.08 --> 4425.48]  En wij hier met z'n tweeën alleen maar soort van heigend overweldigd zitten praten.
[4425.52 --> 4426.48]  Ja, dit is gewoon een nieuw ding.
[4426.60 --> 4426.88]  Canvas.
[4427.14 --> 4428.28]  Maar laten we erbij veel staan.
[4428.50 --> 4431.56]  Dit was de volgende dag waar ze iets groots aankondigden.
[4431.70 --> 4432.10]  Canvas.
[4432.40 --> 4435.54]  Het is eigenlijk een iets andere interface voor ChatGPT.
[4435.54 --> 4438.20]  Waarbij je een soort van digitale werkruimte krijgt.
[4438.28 --> 4442.80]  Waarin je makkelijker kan schrijven, zou ik zeggen.
[4443.36 --> 4444.96]  Dus het is een interface met een zijscherm.
[4445.04 --> 4447.90]  Zoals we dat bij Anthropic van Claude gewend zijn.
[4448.00 --> 4450.32]  Dat je een zijscherm hebt waarin je resultaat krijgt.
[4450.38 --> 4451.82]  En dat je aan de linkerkant chat.
[4452.38 --> 4454.50]  Waardoor je kan interacteren met elkaar.
[4454.76 --> 4456.24]  Wat handig is als je iets aan het schrijven bent.
[4456.34 --> 4456.94]  En je zegt bijvoorbeeld.
[4457.34 --> 4458.60]  Maak de toon nu iets anders.
[4458.92 --> 4460.56]  Dat dat niet een één lang chatgesprek is.
[4460.60 --> 4462.06]  Maar dat je twee dingen naast elkaar hebt.
[4462.12 --> 4463.66]  Waardoor je overzicht hebt van wat je gaat doen.
[4463.66 --> 4467.20]  Nu heeft ChatGPT daar een stap bovenop gedaan.
[4467.32 --> 4468.56]  Inderdaad in de interface.
[4469.14 --> 4470.74]  Door het concept te introduceren.
[4470.78 --> 4472.06]  Wat we allemaal kennen van Google Docs.
[4472.14 --> 4473.52]  Namelijk opmerkingen.
[4473.76 --> 4475.82]  Dus wat je nu kan doen is een tekst schrijven.
[4476.26 --> 4477.56]  Je kan zelfs als een Google Doc.
[4477.62 --> 4479.86]  Kun je beginnen met schrijven in een leeg canvas.
[4480.60 --> 4481.78]  In je chatclient.
[4481.88 --> 4483.84]  Het begint meer te voelen als een word editor.
[4484.02 --> 4484.56]  Wat dat betreft.
[4485.08 --> 4486.02]  En dan kun je dus vragen.
[4486.26 --> 4486.78]  Wat zijn.
[4487.18 --> 4487.74]  Weet ik veel.
[4488.66 --> 4489.06]  Highlight.
[4489.48 --> 4490.58]  Dit werkt dus nu gewoon.
[4490.66 --> 4491.50]  Dit kun je nu gebruiken.
[4491.78 --> 4492.18]  Highlight.
[4492.18 --> 4496.76]  Met alle punten waarbij ik taalfout heb gemaakt.
[4497.00 --> 4497.10]  Of.
[4497.66 --> 4501.10]  Je bent een expert op het gebied van X.
[4501.50 --> 4503.14]  Welk commentaar zou jij erin zetten.
[4503.30 --> 4503.64]  Of nou ja.
[4503.84 --> 4505.76]  Kijk maar waar je creativiteit je brengt.
[4505.80 --> 4507.78]  Je stuurt hem op naar een collega voor een proefreadie.
[4507.84 --> 4509.16]  Je krijgt hem terug met 20 comments.
[4509.44 --> 4513.58]  En dan highlight hij dus de plekken die hij zou veranderen.
[4513.64 --> 4514.80]  Met zo'n gele highlighter erachter.
[4514.88 --> 4516.70]  En dan komt er zo'n tekstballonnetje naast.
[4516.70 --> 4517.38]  En dan kun je hem dus.
[4517.48 --> 4519.90]  Net zoals in Microsoft Word of in Google Docs.
[4520.22 --> 4521.76]  Kun je hem accepten of rejecten.
[4521.76 --> 4525.06]  En dan herschraaakt hij alleen maar dat deel van de tekst.
[4526.04 --> 4532.22]  En op deze manier kun je veel fijnmaziger eigenlijk teksten beïnvloeden.
[4532.64 --> 4534.94]  Ik vind OpenAI nog steeds niet de beste schrijver.
[4535.06 --> 4535.88]  Want dat lijft klopt.
[4536.02 --> 4538.34]  Dus het is een beetje jammer dat dit in OpenAI's tool zit.
[4538.48 --> 4538.68]  Maar oké.
[4538.68 --> 4541.18]  En ze hebben allemaal dingen toegevoegd.
[4541.24 --> 4544.46]  Als dat je bijvoorbeeld het leesniveau kan veranderen van een tekst met een drop-down.
[4545.12 --> 4546.82]  Dat hij emojis kan toevoegen.
[4547.02 --> 4549.14]  Dat was wel een moment voor mij dat ik even moest accepteren.
[4549.32 --> 4550.68]  Dat hij emojis toevoegt aan een tekst.
[4550.72 --> 4552.38]  En dat ze daar een speciale interface voor hebben gebouwd.
[4552.46 --> 4553.30]  Dat zijn wel de momenten.
[4553.42 --> 4554.94]  Ik heb ooit Ethan Mollek zien zeggen.
[4555.02 --> 4559.08]  Op het moment dat je ziet dat AI Labs zich te veel op interfaces gaan richten.
[4559.08 --> 4565.94]  Dan is dat een teken dat hun de soort van de progressie van het model dat erachter zit aan het stagneren is.
[4566.14 --> 4566.56]  Oh grappig.
[4566.92 --> 4570.54]  Want anders zouden ze hun aandacht wel richten op dat werk materiële zaak.
[4570.62 --> 4572.78]  En toen ik ze emojis zag toevoegen aan een tekst.
[4572.78 --> 4574.00]  Dan voelde je een beetje buikpijn.
[4574.14 --> 4574.54]  Oh ja.
[4574.90 --> 4577.58]  Ik denk dat in dat opzicht, een grappige teken is dat trouwens.
[4577.76 --> 4579.66]  Want daar moet ik nog even wat langer over nadenken.
[4579.80 --> 4581.34]  Maar wat ik er nog in wilde fietsen.
[4581.46 --> 4583.02]  Die gaan we niet helemaal uitdiepen vandaag.
[4583.10 --> 4584.70]  Die bewaren we voor een andere aflevering.
[4584.70 --> 4587.56]  Maar is het hele idee dat die tekstinterface.
[4587.56 --> 4590.26]  Dus praten met AI via tekst of met woorden.
[4590.62 --> 4593.60]  Kletsen alsof je met Her, Scarlett Johansson.
[4594.28 --> 4596.48]  Dat daar een beetje een soort rare aanname in zit.
[4596.64 --> 4599.96]  Dat de tijd van de grafische gebruikersinterface.
[4600.06 --> 4600.60]  De GUIs.
[4601.26 --> 4604.04]  Rondklikken op knoppies en scrollen in tabellen.
[4604.46 --> 4606.30]  Dat dat dan voorbij zou zijn ofzo.
[4606.42 --> 4612.64]  Terwijl ik denk dat er heel veel zaken zijn die je als een gesprek het beste kunt doen.
[4612.64 --> 4616.40]  Bijvoorbeeld een Socrates dialoog voeren met een AI.
[4616.40 --> 4618.86]  Om tot de diepere kern te komen van je gedachten.
[4619.60 --> 4624.24]  Of ik doe even een samenvatting maken samen met AI van een sales call.
[4624.54 --> 4625.02]  Dat soort dingen.
[4625.22 --> 4627.40]  Die toepassingen die ploffen nu ook uit elkaar.
[4627.52 --> 4628.78]  Want mensen vinden dat helemaal te gek.
[4629.38 --> 4632.62]  Maar er zijn ook heel veel dingen die jij nu op de computer al kan.
[4633.04 --> 4635.08]  Die best wel goed gaan met een grafische interface.
[4635.30 --> 4637.08]  Die muis ofzo of die cursor.
[4637.50 --> 4638.56]  Die hoeft echt niet zomaar weg.
[4638.66 --> 4640.00]  Apple heeft het geprobeerd met de iPad.
[4640.12 --> 4641.30]  Die zit er inmiddels op die cursor.
[4641.30 --> 4642.92]  Dus die hebben we toch wel nodig gehad.
[4642.92 --> 4644.80]  En niet alleen maar de oudere generatie.
[4645.44 --> 4649.18]  Dus waar we later nog eens in gaan duiken tijdens Poki is.
[4650.74 --> 4653.40]  Is AI wel een chatachtige interface?
[4653.62 --> 4656.18]  Ben jij straks wel de hele dag met je computer aan het praten?
[4656.76 --> 4659.24]  Of komt er een muiscursor in beeld van OpenAI?
[4659.54 --> 4660.86]  Nou dat kan ik je al vertellen ja.
[4661.32 --> 4666.20]  En is het ook zo dat dingen veel meer zoals perplexity in nieuwe widgets getoond worden?
[4666.20 --> 4669.52]  Er is nog best wel een soort greenfield zoals ze dat noemen.
[4669.72 --> 4675.46]  Open velden van potentiële interactie metaforen.
[4675.54 --> 4676.78]  Die nog niet uitgediept zijn.
[4676.84 --> 4681.36]  Dus mijn lezing van dat emoji pickertje en die comments is ietsje positiever.
[4681.42 --> 4684.52]  Dat ik denk oh wat leuk dat er ook bij OpenAI tijd is.
[4684.66 --> 4685.84]  Als anders zit na me te grijzen.
[4686.10 --> 4691.86]  Dat er bij OpenAI ook tijd is om na te denken over meer dan alleen maar chatten met AI.
[4691.86 --> 4702.04]  Nou en in diezelfde video hadden ze ook diezelfde zijscherm die canvas kun je ook gebruiken om programmeercode in te draaien.
[4702.26 --> 4702.88]  Te runnen.
[4703.06 --> 4706.36]  Ja want het is eigenlijk artifacts van Cloud met een run button erbij.
[4706.38 --> 4706.40]  Met een run button erbij.
[4706.40 --> 4706.92]  Met een run button.
[4707.32 --> 4707.46]  Ja.
[4707.72 --> 4708.48]  Best wel gek.
[4708.70 --> 4714.98]  En dan wat ik mooi vond was als je dan iets geprogrammeerd hebt of dat ding iets geprogrammeerd heeft wat niet werkt.
[4715.12 --> 4716.16]  Want dat gebeurt natuurlijk de hele tijd.
[4716.42 --> 4719.56]  Dan kan je dus nu die error afvangen en dan zit daar een knopje bij.
[4719.56 --> 4721.34]  En dat vond ik echt ik wil dat op een t-shirt.
[4721.34 --> 4723.20]  De knopje luidt fix bug.
[4723.56 --> 4724.16]  Wauw.
[4724.18 --> 4724.98]  En dan gaat hij dat doen.
[4725.44 --> 4726.76]  Ik vind dat toch wel de toekomst.
[4726.76 --> 4732.14]  En dan loop jij overdag en dan loop jij buiten en dan zie jij die samenleving en dan zie je toch wat dingen misgaan.
[4732.22 --> 4733.44]  En dan denk jij fix bug.
[4733.50 --> 4733.94]  Fix bug.
[4734.50 --> 4736.80]  Nou de 12 days of shipment zijn nog bezig.
[4737.02 --> 4737.78]  We zijn op de helft.
[4738.34 --> 4740.84]  Dus we zijn nog maar op de helft zou ik zeggen.
[4741.02 --> 4742.44]  Denk je dat ze Orion nog gaan droppen?
[4742.54 --> 4742.90]  Orion.
[4743.58 --> 4745.46]  Het GPT-4 in een halfachtig ding.
[4745.56 --> 4748.94]  Ja nou dat is wel waar Sam Altman naar lijkt te hinten op Twitter.
[4748.94 --> 4758.42]  Er was een iemand op Twitter die spotte met een scherp oog op de open airwebset een verstopte verwijzing naar een limited preview van GPT-4 in een half.
[4759.24 --> 4763.48]  En Sam Altman leek dit direct of indirect te bevestigen toen iemand dat opmerkte.
[4764.10 --> 4766.70]  En ook zei dat de prestaties van O1 zouden aflakken.
[4766.70 --> 4769.28]  De antwoorden hij veel betekenend 12 days of shipment.
[4769.78 --> 4771.38]  En dit was pas dag 1.
[4771.74 --> 4777.00]  En misschien kunnen wij onszelf dan eventjes indekken voor als dit waarschijnlijk over een uur geloven wordt.
[4777.00 --> 4778.46]  Want dat is ons leven inmiddels.
[4779.10 --> 4780.94]  Er is natuurlijk nog steeds een kans.
[4781.38 --> 4783.22]  Want in de LM Arena.
[4783.40 --> 4784.28]  LM SIS Arena.
[4784.44 --> 4788.64]  Dat is eigenlijk de arena waar taalmodellen subjectief worden getest aan de hand van mensen.
[4788.92 --> 4791.28]  Dus mensen die praten de hele dag met taalmodellen.
[4791.74 --> 4793.04]  Die weten niet waar ze mee praten.
[4793.14 --> 4794.02]  En die ranken die dan.
[4794.36 --> 4797.70]  En daar rankt Gemini 2 heel hoog nu.
[4798.32 --> 4799.66]  Eigenlijk zijn ze er.
[4800.32 --> 4802.28]  Bol loopt voorop in de wedstrijd.
[4802.74 --> 4805.26]  En dan heb je natuurlijk toch kans dat de echte bol nog komt.
[4805.50 --> 4805.66]  Namelijk.
[4806.08 --> 4808.46]  En dat is GPT-4 in een half ineens weer.
[4808.62 --> 4808.86]  Woep.
[4809.18 --> 4810.16]  Gemini wegblaast.
[4810.28 --> 4812.64]  En dan blijkt Google toch weer zes maanden achter te lopen.
[4813.74 --> 4814.14]  Ja.
[4814.44 --> 4815.50]  Ik wil het toch even indekken.
[4815.50 --> 4815.74]  Ja.
[4816.12 --> 4817.42]  Ja, dit zal weer gaan gebeuren.
[4817.96 --> 4818.48]  Nou, hoe dan ook.
[4818.54 --> 4823.54]  Straks gaan we nog even hebben over hoe OnlyFans makers gered worden door de hulp van AI.
[4823.70 --> 4824.88]  Dat wil ik toch nog even teasen.
[4825.14 --> 4826.24]  Eerste tip van de week.
[4826.24 --> 4831.02]  Want dat Canvas, dat hebben wij verder uitgewerkt in onze Newsbrief AI Report.
[4831.74 --> 4838.48]  En we hebben helemaal uitgewerkt hoe je Canvas eigenlijk kan gebruiken om je te helpen als redacteur met teksten.
[4838.70 --> 4840.60]  Hoe je teksten het beste kan verfijnen.
[4840.92 --> 4846.82]  Hoe je een effectieve redacteur maakt van ChatGPT.
[4846.96 --> 4848.20]  Daar zijn allemaal prompt voor.
[4848.38 --> 4850.22]  Die hebben we voor je op een rijtje gezet.
[4850.76 --> 4855.98]  Die zelfs doorlopen tot dat alle punten en commas op het eind helemaal goed staan.
[4856.24 --> 4861.30]  En daarmee kun je eigenlijk ChatGPT in je workflow verwerken in de praktijk.
[4861.42 --> 4864.20]  Want het is leuk dat het op theoretisch niveau kan allemaal.
[4864.36 --> 4866.86]  Maar je moet nog maar productiviteitswinst eruit halen.
[4867.36 --> 4869.22]  Dat doen we in onze Newsbrief AI Report.
[4869.42 --> 4872.52]  Wil je dat weten en wil je daarop abonneren?
[4872.58 --> 4873.70]  Dan ga je naar AI Report.
[4873.70 --> 4874.82]  punt e-mail.
[4876.82 --> 4881.10]  Oké Witte, als toetje van deze lange, lange, lange aflevering.
[4881.58 --> 4883.82]  Toch nog even iets frivols.
[4884.14 --> 4889.64]  Je had het vorige week over YouTubers die geautomatiseerd comments kunnen plaatsen.
[4889.76 --> 4891.00]  Omdat YouTube AI gebruikt.
[4891.00 --> 4892.94]  getraind op individuele creators.
[4893.60 --> 4897.26]  En die dus in de tone of voice van een specifieke YouTuber kunnen reageren op gebruikers.
[4897.80 --> 4901.06]  Datzelfde probleem blijkt te hebben OnlyFans makers.
[4902.04 --> 4904.40]  Die gesprekken voeren met fans.
[4905.00 --> 4906.32]  En heb ik mij laten vertellen Witte.
[4906.60 --> 4908.68]  Heel veel geld verdienen aan die gesprekken met fans.
[4908.94 --> 4910.30]  Je hoorde van een vriend van een vriend.
[4910.30 --> 4911.50]  Ja, ik hoorde van een vriend van een vriend.
[4911.58 --> 4914.96]  Dat ze zeg maar, je hebt inkomsten uit de paywall bij OnlyFans.
[4915.08 --> 4916.48]  Dus daar kun je je voetofoto's op zetten.
[4917.06 --> 4918.96]  Tenminste, dat is hypothetisch.
[4919.46 --> 4923.84]  En dan kun je ook nog geld verdienen door mensen individueel toe te spreken.
[4924.24 --> 4925.30]  Die dan tippen.
[4926.44 --> 4928.30]  Voor extra dingen één op één zeg maar.
[4928.76 --> 4932.18]  En dat is iets waar dus AI bij ingezet wordt tegenwoordig.
[4932.28 --> 4935.30]  En dat is een vervolg op een lange tradities.
[4936.12 --> 4938.58]  Waarbij chatters, ik ben in deze wereld gedoken.
[4938.58 --> 4939.62]  Ik vind het iets fascinerends.
[4939.62 --> 4943.62]  Dat chatters uit landen als Filipijnen, Pakistan en India ingehuurd werden.
[4943.76 --> 4947.14]  Om de OnlyFans creators, hoe moet je dat noemen?
[4948.98 --> 4949.38]  Imbiteerden.
[4949.52 --> 4951.68]  Om dus voor hen met die fans te praten.
[4951.76 --> 4954.30]  Want het was niet te doen om dat door de creators zelf te laten doen.
[4954.40 --> 4956.90]  Dus daar werden mensen uit de Filipijnen voor gebruikt.
[4957.50 --> 4960.12]  En die worden dus nu overbodig gemaakt door AI.
[4960.28 --> 4961.82]  En dat biedt allerlei voordelen.
[4962.04 --> 4963.52]  Anders dan economische voordelen.
[4963.92 --> 4965.58]  Ik weet hoe cynisch het allemaal is hoor.
[4965.58 --> 4969.58]  Maar bijvoorbeeld dat er tools zijn zoals Flirtflow.
[4969.62 --> 4972.68]  Chatter Charms en Super Creator.
[4973.34 --> 4980.14]  Die helpen bij het in kaart brengen van wie waarschijnlijk het meeste geld gaat uitvoeren tijdens een op een gesprekken.
[4980.64 --> 4983.04]  En die zet hij dan bovenaan in de inbox.
[4983.04 --> 4987.32]  Is het in OnlyFans gebouwd of zijn het externe tools?
[4987.42 --> 4990.78]  Het zijn externe tools, maar die wel inhaken op OnlyFans.
[4990.86 --> 4996.10]  Omdat de gebruikersvoorwaarden van OnlyFans wel vereisen dat er nog een mens op oké drukt.
[4996.86 --> 4999.94]  Dus je mag AI gebruiken om een draft te schrijven.
[5000.04 --> 5001.04]  Dat is wat die tools doen.
[5001.22 --> 5003.76]  En die gaan dus ook bedenken waar ze op moeten reageren.
[5003.82 --> 5008.54]  Die houden dus ook bij welke gebruiker in het verleden heeft geld gegeven tijdens een een-op-een gesprek.
[5008.54 --> 5011.92]  Maar is na lange tijd weer opeens opnieuw online gekomen.
[5012.08 --> 5013.60]  Die gaat die bot gelijk op af.
[5013.84 --> 5016.54]  Omdat die indexeert wie die goed geld kan aftroggelen.
[5017.82 --> 5021.12]  En dan moet er dus wel nog iemand zijn bij de redactie.
[5021.20 --> 5022.54]  Stel ik mezelf voor van die creator.
[5023.02 --> 5024.42]  Die dan op oké drukt.
[5025.32 --> 5025.44]  Nou.
[5026.18 --> 5030.26]  Is dit de dystopie waar je op het eind even de week mee kan insturen?
[5030.28 --> 5032.38]  Ik weet niet of ik dit zo snel in Europa wil hebben.
[5032.50 --> 5033.08]  Ja precies.
[5033.30 --> 5034.28]  Nou zijn we toch weer terug.
[5034.42 --> 5035.74]  Nou als kers op de taart.
[5036.14 --> 5036.82]  Nog een reclame.
[5036.82 --> 5040.08]  Blijf erbij.
[5040.26 --> 5043.32]  Want we krijgen een ongelooflijk mooie einde van deze aflevering.
[5043.50 --> 5048.80]  Hoeveel uur kost het je om gegevens handmatig te laten verwijderen bij grote datamakelaars?
[5048.86 --> 5049.68]  Dat hebben we uitgezocht.
[5049.78 --> 5051.36]  Meer dan 131 uur.
[5051.44 --> 5053.76]  Dat is bijna 5,5 dagen non-stop werk.
[5054.24 --> 5056.56]  En gelukkig is er een bedrijf die dat voor jou doet.
[5056.68 --> 5057.86]  Als je dat belangrijk vindt.
[5057.86 --> 5059.68]  Dat jouw data niet overal rondzwerven.
[5060.16 --> 5061.04]  En dat doet InCogni.
[5061.04 --> 5066.96]  Met meer dan 20 miljoen succesvolle dataverwijderingen en dekking van meer dan 175 datamakelaars.
[5067.00 --> 5069.18]  Ik wist niet eens wat ze 175 datamakelaars waren.
[5069.38 --> 5069.56]  Maar oké.
[5069.90 --> 5072.38]  Is InCogni de expert het beschermen van jouw privacy.
[5072.66 --> 5074.84]  Zodra je je aanmeldt zie je direct resultaat.
[5075.02 --> 5076.16]  Minder spamtelefantjes.
[5076.36 --> 5077.42]  Minder ongevraagde e-mails.
[5077.58 --> 5078.38]  En phishingpogingen.
[5078.88 --> 5081.56]  Je persoonlijke gegevens worden moeilijker vindbaar voor cybercriminelen.
[5081.56 --> 5086.86]  En voor bedrijven die de gebruiken voor hun foute malafide praktijken.
[5087.56 --> 5088.54]  Maar het gaat verder dan dat.
[5088.74 --> 5091.48]  Door je data te beschermen verklein je ook je financiële risico's.
[5091.78 --> 5097.92]  Verzekeraars, banken en potentiële werkgevers krijgen geen toegang meer tot jouw achtergrondgegevens zonder jouw toestemming.
[5098.68 --> 5099.86]  Wil jij ook je privacy terug?
[5099.94 --> 5101.34]  Ga dan nu naar incogni.com.
[5101.42 --> 5106.18]  En krijg 60% korting op jouw InCogni account.
[5108.34 --> 5109.72]  Wiese, ik haal adem.
[5109.94 --> 5110.32]  Mijn god.
[5111.56 --> 5114.52]  En dit was denk ik een kwart van de aankondigingen.
[5115.12 --> 5115.80]  We hebben echt ons best.
[5115.92 --> 5116.28]  Sorry man.
[5116.84 --> 5118.46]  Zouden wij echt een kwart besproken?
[5118.52 --> 5119.14]  Ja, ik denk het wel.
[5119.46 --> 5121.44]  Ja, want ik was eigenlijk nog niet helemaal klaar.
[5121.52 --> 5122.06]  Het was echt veel.
[5122.12 --> 5122.96]  En er kwam nog meer bij.
[5123.12 --> 5124.54]  En die 12 dagen zijn nog niet klaar.
[5124.66 --> 5125.14]  Dus, hé.
[5126.30 --> 5127.40]  Dit was Poki.
[5127.60 --> 5128.96]  Met Dang en Sam Hengeveld voor de edit.
[5129.22 --> 5131.36]  Wil je een lezing van Wiese of van mij over AI?
[5131.48 --> 5131.84]  Dat kan.
[5132.06 --> 5133.88]  Daarvoor kun je meedoen naar lezing.poki.show.
[5134.00 --> 5136.52]  Vergeet je niet te abonneren op AI-report.email.
[5137.24 --> 5139.00]  Volgende week zijn we bij je terug.
[5139.00 --> 5141.96]  En dan gaan we bespreken niet wat we vandaag gemist hebben.
[5141.96 --> 5143.46]  Want dat is gewoon weg.
[5143.96 --> 5145.84]  Maar wel al het nieuwe wat dan is uitgekomen.
[5146.18 --> 5146.42]  Tot dan.
[5146.68 --> 5147.04]  Tot dan.
[5147.04 --> 5166.26]  18 plus speelbewust.
[5166.50 --> 5169.10]  1 januari valt die gegarandeerd.
[5169.42 --> 5172.72]  De postcode kan je van 59,7 miljoen.
[5172.72 --> 5175.10]  Het kan overal in Nederland gebeuren.
[5175.34 --> 5176.84]  Dus ook bij u in de straat.
[5177.64 --> 5179.70]  59,7 miljoen.
[5179.98 --> 5180.80]  Speel ook mee.
[5181.86 --> 5184.46]  Ga naar postcode loterij.nl.
